import streamlit as st
import pandas as pd
import numpy as np
import wbdata
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import shap
import warnings
import os
from datetime import datetime

warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="An√°lise Econ√¥mica e Proje√ß√µes",
    page_icon="üìà",
    layout="wide"
)

# Dicion√°rio expandido de indicadores
INDICADORES = {
    # Indicadores Originais
    "NY.GDP.PCAP.KD": "PIB_per_capita",
    "NE.GDI.FTOT.CD": "Formacao_Bruta_Capital", 
    "SE.ADT.1524.LT.ZS": "Alfabetizacao_Jovens",
    "SL.TLF.CACT.ZS": "Participacao_Forca_Trabalho",
    "IT.NET.USER.ZS": "Cobertura_Internet",
    "NE.EXP.GNFS.CD": "Valor_Exportacoes",
    "NY.GNP.PCAP.CD": "Renda_Nacional_Bruta_per_Capita",
    "EG.ELC.ACCS.ZS": "Acesso_Eletricidade",
    "SI.POV.GINI": "Gini",
    "SL.UEM.TOTL.ZS": "Desemprego",
    "SE.PRM.CMPT.ZS": "Conclusao_Ensino_Primario",
    "NE.CON.PRVT.CD": "Consumo_Familias",
    "SH.H2O.BASW.ZS": "Cobertura_Agua_Potavel",
    # Novos Indicadores
    "FP.CPI.TOTL.ZG": "Inflacao_Anual_Consumidor",
    "BX.KLT.DINV.CD.WD": "Investimento_Estrangeiro_Direto",
    "SP.DYN.LE00.IN": "Expectativa_de_Vida",
    "SE.XPD.TOTL.GD.ZS": "Gastos_Governamentais_Educacao",
    "GC.DOD.TOTL.GD.ZS": "Divida_Governo_Central_perc_PIB",
    "IQ.CPA.BREG.XQ": "Qualidade_Regulatoria",
    "MS.MIL.XPND.GD.ZS": "Gastos_Militares_perc_PIB",
    "TX.VAL.TECH.MF.ZS": "Exportacoes_Alta_Tecnologia_perc"
}

# Vari√°veis monet√°rias para transforma√ß√£o logar√≠tmica
VARIAVEIS_MONETARIAS = [
    'PIB_per_capita', 'Formacao_Bruta_Capital', 'Valor_Exportacoes',
    'Renda_Nacional_Bruta_per_Capita', 'Consumo_Familias',
    'Investimento_Estrangeiro_Direto'
]

@st.cache_data
def carregar_dados_banco_mundial(paises, anos):
    """
    Carrega dados do Banco Mundial com cache local para evitar erro 429.
    """
    cache_file = "dados_banco_mundial.csv"
    
    try:
        # Tenta carregar dados do cache local
        st.info("üîÑ Tentando carregar dados do cache local...")
        df_cached = pd.read_csv(cache_file)
        
        # Verifica se os dados em cache cobrem os pa√≠ses e anos solicitados
        df_cached['date'] = pd.to_numeric(df_cached['date'])
        paises_cache = df_cached['country'].unique()
        anos_cache = df_cached['date'].unique()
        
        # Filtra pelos pa√≠ses e anos solicitados
        df_filtered = df_cached[
            (df_cached['country'].isin(paises)) & 
            (df_cached['date'].isin(anos))
        ]
        
        if len(df_filtered) > 0:
            st.success(f"‚úÖ Dados carregados do cache! {len(df_filtered)} registros encontrados.")
            return df_cached, df_filtered
        else:
            st.warning("‚ö†Ô∏è Cache n√£o cont√©m dados suficientes para os pa√≠ses/anos selecionados.")
            raise FileNotFoundError("Cache insuficiente")
            
    except (FileNotFoundError, pd.errors.EmptyDataError):
        # Se n√£o h√° cache ou √© insuficiente, baixa da API
        st.info("üåê Baixando dados do Banco Mundial...")
        
        try:
            # Baixa dados da API
            df_raw = wbdata.get_dataframe(
                INDICADORES,
                country=paises,
                data_date=anos
            )
            
            if df_raw is not None and not df_raw.empty:
                # Salva no cache para uso futuro
                df_raw.reset_index().to_csv(cache_file, index=False)
                st.success(f"‚úÖ Dados baixados e salvos no cache! {len(df_raw)} registros.")
                
                # Filtra pelos pa√≠ses e anos solicitados
                df_filtered = df_raw.reset_index()
                df_filtered = df_filtered[
                    (df_filtered['country'].isin(paises)) & 
                    (df_filtered['date'].isin(anos))
                ]
                
                return df_raw, df_filtered
            else:
                st.error("‚ùå Erro ao baixar dados da API do Banco Mundial.")
                return None, None
                
        except Exception as e:
            st.error(f"‚ùå Erro ao acessar API do Banco Mundial: {str(e)}")
            return None, None

def processar_dados(df_raw):
    """
    Processa e limpa os dados com uma estrat√©gia de imputa√ß√£o robusta
    para maximizar a reten√ß√£o de pa√≠ses.
    """
    if df_raw is None or df_raw.empty:
        return None, None
    
    df = df_raw.copy().reset_index()
    
    # Renomear colunas
    if 'country' in df.columns:
        df.rename(columns={'country': 'Pa√≠s'}, inplace=True)
    if 'date' in df.columns:
        df.rename(columns={'date': 'Ano'}, inplace=True)
        df['Ano'] = pd.to_numeric(df['Ano'])
    
    if 'Pa√≠s' not in df.columns or 'Ano' not in df.columns:
        st.error("As colunas 'Pa√≠s' e/ou 'Ano' n√£o est√£o dispon√≠veis.")
        return None, None
    
    df = df.sort_values(by=['Pa√≠s', 'Ano'])
    
    # --- ESTRAT√âGIA DE IMPUTA√á√ÉO MULTIN√çVEL ---
    indicadores_a_processar = [col for col in df.columns if col not in ['Pa√≠s', 'Ano']]
    
    # Guarda informa√ß√£o sobre dados faltantes antes da imputa√ß√£o
    dados_faltantes_antes = df[indicadores_a_processar].isnull().sum().sum()
    total_pontos = len(df) * len(indicadores_a_processar)
    
    # Aplica imputa√ß√£o por pa√≠s
    def imputar_grupo(group):
        result = group.set_index('Ano')[indicadores_a_processar]
        result = result.interpolate(method='linear', limit_direction='both')  # 1. Interpola√ß√£o linear
        result = result.ffill()  # 2. Forward-fill para bordas iniciais
        result = result.bfill()  # 3. Backward-fill para bordas finais
        return result
    
    df_processado = df.groupby('Pa√≠s', group_keys=False).apply(
        lambda group: imputar_grupo(group)
    ).reset_index()
    
    # Como √∫ltimo recurso, preenche com 0
    df_processado.fillna(0, inplace=True)
    
    # Relat√≥rio de qualidade
    dados_imputados = dados_faltantes_antes - df_processado[indicadores_a_processar].isnull().sum().sum()
    
    # --- Prepara√ß√£o para o Modelo ---
    df_model = df_processado.copy().set_index(['Pa√≠s', 'Ano'])
    
    # Remove a vari√°vel alvo dos preditores
    if 'PIB_per_capita' in df_model.columns:
        target = df_model['PIB_per_capita']
        predictors_df = df_model.drop(columns=['PIB_per_capita'])
    else:
        st.error("A coluna 'PIB_per_capita' n√£o foi encontrada ap√≥s o processamento.")
        return None, None
    
    # Engenharia de vari√°veis (lags)
    for var in predictors_df.columns:
        df_model[f'{var}_lag1'] = predictors_df.groupby('Pa√≠s')[var].shift(1)
    
    # Remove NaNs dos lags (primeira linha de cada pa√≠s)
    df_model = df_model.dropna()
    
    return df_processado, df_model

def aplicar_transformacao_log(df, colunas_monetarias, aplicar=True):
    """
    Aplica ou reverte transforma√ß√£o logar√≠tmica nas vari√°veis monet√°rias.
    """
    if df is None:
        return None
    
    df_transformed = df.copy()
    
    for col in colunas_monetarias:
        if col in df_transformed.columns:
            if aplicar:
                # Aplica log1p (log(1+x) para lidar com zeros)
                df_transformed[col] = np.log1p(df_transformed[col].clip(lower=0))
            else:
                # Reverte com expm1
                df_transformed[col] = np.expm1(df_transformed[col])
    
    return df_transformed

def treinar_modelos(df_model, usar_log=False):
    """
    Treina m√∫ltiplos modelos de machine learning.
    """
    if df_model is None or df_model.empty:
        return None
    
    # Preparar dados
    df_work = df_model.copy()
    
    if usar_log:
        # Aplicar transforma√ß√£o logar√≠tmica
        colunas_para_log = [col for col in VARIAVEIS_MONETARIAS if col in df_work.columns]
        colunas_para_log += [f"{col}_lag1" for col in VARIAVEIS_MONETARIAS if f"{col}_lag1" in df_work.columns]
        df_work = aplicar_transformacao_log(df_work, colunas_para_log, aplicar=True)
    
    # Separar features e target
    feature_cols = [col for col in df_work.columns if col != 'PIB_per_capita']
    X = df_work[feature_cols]
    y = df_work['PIB_per_capita']
    
    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Modelos
    modelos = {
        'XGBoost': xgb.XGBRegressor(
            n_estimators=100, 
            max_depth=6, 
            learning_rate=0.1, 
            random_state=42
        ),
        'Random Forest': RandomForestRegressor(
            n_estimators=100, 
            max_depth=10, 
            random_state=42
        ),
        'Regress√£o Linear': LinearRegression()
    }
    
    resultados = {}
    
    for nome, modelo in modelos.items():
        # Treinar
        modelo.fit(X_train, y_train)
        
        # Predi√ß√µes
        y_pred_train = modelo.predict(X_train)
        y_pred_test = modelo.predict(X_test)
        
        # Se usou log, reverter as predi√ß√µes
        if usar_log:
            y_pred_train = np.expm1(y_pred_train)
            y_pred_test = np.expm1(y_pred_test)
            y_train_orig = np.expm1(y_train)
            y_test_orig = np.expm1(y_test)
        else:
            y_train_orig = y_train
            y_test_orig = y_test
        
        # M√©tricas
        mae_test = mean_absolute_error(y_test_orig, y_pred_test)
        rmse_test = np.sqrt(mean_squared_error(y_test_orig, y_pred_test))
        r2_test = r2_score(y_test_orig, y_pred_test)
        
        resultados[nome] = {
            'modelo': modelo,
            'mae': mae_test,
            'rmse': rmse_test,
            'r2': r2_test,
            'y_test': y_test_orig,
            'y_pred': y_pred_test,
            'features': feature_cols
        }
    
    return resultados, X_train, X_test, y_train, y_test

def gerar_projecao_com_cenario(pais, modelo, df_processado, ano_final, 
                               indicador_para_chocar=None, variacao_percentual=0, 
                               usar_log=False):
    """
    Gera proje√ß√£o com cen√°rio espec√≠fico para an√°lise de sensibilidade.
    """
    # Preparar dados do pa√≠s
    df_pais = df_processado[df_processado['Pa√≠s'] == pais].copy()
    if df_pais.empty:
        return None
    
    df_pais = df_pais.sort_values('Ano')
    ultimo_ano = df_pais['Ano'].max()
    
    # Se o ano final j√° existe nos dados, usar dados hist√≥ricos
    if ano_final <= ultimo_ano:
        return df_pais[df_pais['Ano'] <= ano_final]
    
    projecoes = []
    
    # Dados base para proje√ß√£o
    dados_base = df_pais.copy()
    
    for ano in range(ultimo_ano + 1, ano_final + 1):
        # Pegar dados do ano anterior
        dados_anterior = dados_base[dados_base['Ano'] == (ano - 1)].iloc[0]
        
        # Preparar features para predi√ß√£o
        features_dict = {}
        feature_cols = [col for col in dados_anterior.index if col not in ['Pa√≠s', 'Ano', 'PIB_per_capita']]
        
        for col in feature_cols:
            if col.endswith('_lag1'):
                # Para vari√°veis lag, usar o valor do ano anterior
                base_var = col.replace('_lag1', '')
                if base_var in dados_anterior.index:
                    features_dict[col] = dados_anterior[base_var]
                else:
                    features_dict[col] = dados_anterior[col]
            else:
                # Para outras vari√°veis, aplicar cen√°rio se necess√°rio
                valor_base = dados_anterior[col]
                
                if indicador_para_chocar and col == indicador_para_chocar:
                    # Aplicar varia√ß√£o percentual
                    valor_base = valor_base * (1 + variacao_percentual / 100)
                
                features_dict[col] = valor_base
        
        # Criar array de features na ordem correta
        feature_names = modelo.feature_names_in_ if hasattr(modelo, 'feature_names_in_') else list(features_dict.keys())
        X_pred = np.array([features_dict.get(name, 0) for name in feature_names]).reshape(1, -1)
        
        # Aplicar transforma√ß√£o log se necess√°rio
        if usar_log:
            for i, name in enumerate(feature_names):
                base_name = name.replace('_lag1', '')
                if base_name in VARIAVEIS_MONETARIAS:
                    X_pred[0, i] = np.log1p(max(0, X_pred[0, i]))
        
        # Fazer predi√ß√£o
        pib_pred = modelo.predict(X_pred)[0]
        
        # Reverter log se necess√°rio
        if usar_log:
            pib_pred = np.expm1(pib_pred)
        
        # Criar nova linha
        nova_linha = dados_anterior.copy()
        nova_linha['Ano'] = ano
        nova_linha['PIB_per_capita'] = pib_pred
        
        # Atualizar indicadores com cen√°rio
        if indicador_para_chocar and indicador_para_chocar in nova_linha.index:
            nova_linha[indicador_para_chocar] = nova_linha[indicador_para_chocar] * (1 + variacao_percentual / 100)
        
        # Adicionar √† base de dados para pr√≥xima itera√ß√£o
        dados_base = pd.concat([dados_base, nova_linha.to_frame().T], ignore_index=True)
        projecoes.append(nova_linha)
    
    # Combinar hist√≥rico com proje√ß√µes
    if projecoes:
        df_projecoes = pd.DataFrame(projecoes)
        resultado = pd.concat([df_pais, df_projecoes], ignore_index=True)
    else:
        resultado = df_pais
    
    return resultado.sort_values('Ano')

def calcular_relatorio_qualidade(df_raw):
    """
    Calcula relat√≥rio de qualidade dos dados por pa√≠s.
    """
    if df_raw is None:
        return pd.DataFrame()
    
    df_check = df_raw.copy()
    if hasattr(df_raw, 'reset_index'):
        df_check = df_raw.reset_index()
    
    # Garantir que temos as colunas corretas
    country_col = 'country' if 'country' in df_check.columns else 'Pa√≠s'
    
    if country_col not in df_check.columns:
        return pd.DataFrame()
    
    # Calcular dados faltantes por pa√≠s
    indicadores_cols = [col for col in df_check.columns if col not in [country_col, 'date', 'Ano']]
    
    missing_data_report = df_check.groupby(country_col)[indicadores_cols].apply(
        lambda x: x.isnull().sum().sum() / (len(x.columns) * len(x))
    ).sort_values(ascending=False)
    
    missing_data_report = missing_data_report[missing_data_report > 0] * 100
    
    if not missing_data_report.empty:
        df_report = pd.DataFrame({
            'Pa√≠s': missing_data_report.index, 
            '% de Dados Faltantes (Original)': missing_data_report.values.round(2)
        })
        return df_report
    
    return pd.DataFrame()

def main():
    st.title("üåç An√°lise Econ√¥mica e Proje√ß√µes - PIB per Capita")
    st.markdown("---")
    
    # Sidebar para configura√ß√µes
    st.sidebar.header("‚öôÔ∏è Configura√ß√µes")
    
    # Sele√ß√£o de pa√≠ses
    paises_disponiveis = [
        'BR', 'US', 'CN', 'DE', 'JP', 'GB', 'FR', 'IN', 'IT', 'CA',
        'KR', 'RU', 'AU', 'ES', 'MX', 'ID', 'NL', 'SA', 'TR', 'CH'
    ]
    
    paises_selecionados = st.sidebar.multiselect(
        "Selecione os pa√≠ses:",
        paises_disponiveis,
        default=['BR', 'US', 'CN', 'DE']
    )
    
    # Sele√ß√£o de anos
    ano_inicio = st.sidebar.slider("Ano inicial:", 2000, 2020, 2010)
    ano_fim = st.sidebar.slider("Ano final:", 2021, 2030, 2022)
    anos = list(range(ano_inicio, ano_fim + 1))
    
    # Op√ß√£o de transforma√ß√£o logar√≠tmica
    usar_log = st.sidebar.checkbox("Usar transforma√ß√£o logar√≠tmica para melhorar o modelo")
    
    if not paises_selecionados:
        st.warning("‚ö†Ô∏è Por favor, selecione pelo menos um pa√≠s.")
        return
    
    # Carregar dados
    with st.spinner("üîÑ Carregando dados..."):
        df_raw, df_filtered = carregar_dados_banco_mundial(paises_selecionados, anos)
    
    if df_raw is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar os dados.")
        return
    
    # Salvar no session state
    st.session_state.df_raw = df_raw
    
    # Relat√≥rio de qualidade dos dados
    st.subheader("‚úÖ Qualidade e Cobertura dos Dados")
    df_qualidade = calcular_relatorio_qualidade(df_raw)
    
    if not df_qualidade.empty:
        st.warning("‚ö†Ô∏è Aten√ß√£o: Os pa√≠ses a seguir exigiram preenchimento significativo de dados faltantes, o que pode afetar a precis√£o das proje√ß√µes. Os dados foram preenchidos usando interpola√ß√£o e outras t√©cnicas.")
        st.dataframe(df_qualidade.head(10))
    else:
        st.success("‚úÖ Todos os pa√≠ses selecionados possuem boa cobertura de dados.")
    
    # Processar dados
    with st.spinner("üîß Processando dados..."):
        df_processado, df_model = processar_dados(df_filtered)
    
    if df_processado is None:
        st.error("‚ùå Erro no processamento dos dados.")
        return
    
    # Mostrar estat√≠sticas b√°sicas
    st.subheader("üìä Estat√≠sticas dos Dados")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Pa√≠ses inclu√≠dos", df_processado['Pa√≠s'].nunique())
    with col2:
        st.metric("Per√≠odo de an√°lise", f"{df_processado['Ano'].min()}-{df_processado['Ano'].max()}")
    with col3:
        st.metric("Total de observa√ß√µes", len(df_processado))
    
    # Treinar modelos
    st.subheader("ü§ñ Treinamento de Modelos")
    
    with st.spinner("üèãÔ∏è Treinando modelos..."):
        resultados, X_train, X_test, y_train, y_test = treinar_modelos(df_model, usar_log)
    
    if resultados is None:
        st.error("‚ùå Erro no treinamento dos modelos.")
        return
    
    # Compara√ß√£o de modelos
    st.subheader("üìà Compara√ß√£o de Modelos")
    
    df_comparacao = pd.DataFrame({
        'Modelo': list(resultados.keys()),
        'MAE': [res['mae'] for res in resultados.values()],
        'RMSE': [res['rmse'] for res in resultados.values()],
        'R¬≤': [res['r2'] for res in resultados.values()]
    })
    
    st.dataframe(df_comparacao)
    
    # Selecionar melhor modelo
    melhor_modelo_nome = df_comparacao.loc[df_comparacao['R¬≤'].idxmax(), 'Modelo']
    melhor_modelo = resultados[melhor_modelo_nome]['modelo']
    
    st.success(f"üèÜ Melhor modelo: {melhor_modelo_nome} (R¬≤ = {df_comparacao['R¬≤'].max():.3f})")
    
    # Explicabilidade com SHAP (apenas para modelos baseados em √°rvore)
    if melhor_modelo_nome in ['XGBoost', 'Random Forest']:
        st.subheader("üîç Explicabilidade do Modelo (SHAP)")
        
        try:
            explainer = shap.TreeExplainer(melhor_modelo)
            shap_values = explainer.shap_values(X_test.iloc[:100])  # Usar apenas 100 amostras
            
            # Summary plot
            fig, ax = plt.subplots(figsize=(10, 6))
            shap.summary_plot(shap_values, X_test.iloc[:100], show=False)
            st.pyplot(fig)
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel gerar gr√°ficos SHAP: {str(e)}")
    
    # Proje√ß√µes
    st.subheader("üîÆ Proje√ß√µes Econ√¥micas")
    
    col1, col2 = st.columns(2)
    with col1:
        pais_projecao = st.selectbox("Selecione o pa√≠s:", df_processado['Pa√≠s'].unique())
    with col2:
        ano_projecao = st.slider("Projetar at√© o ano:", 
                                df_processado['Ano'].max() + 1, 
                                df_processado['Ano'].max() + 10, 
                                df_processado['Ano'].max() + 5)
    
    if st.button("üöÄ Gerar Proje√ß√£o"):
        with st.spinner("üîÆ Gerando proje√ß√µes..."):
            df_projecao = gerar_projecao_com_cenario(
                pais_projecao, melhor_modelo, df_processado, ano_projecao, usar_log=usar_log
            )
        
        if df_projecao is not None:
            # Gr√°fico de proje√ß√£o
            fig = px.line(df_projecao, x='Ano', y='PIB_per_capita', 
                         title=f'Proje√ß√£o PIB per Capita - {pais_projecao}')
            
            # Marcar divis√£o entre hist√≥rico e proje√ß√£o
            ultimo_ano_historico = df_processado[df_processado['Pa√≠s'] == pais_projecao]['Ano'].max()
            fig.add_vline(x=ultimo_ano_historico, line_dash="dash", line_color="red",
                         annotation_text="In√≠cio das Proje√ß√µes")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Tabela com valores projetados
            df_projetado = df_projecao[df_projecao['Ano'] > ultimo_ano_historico]
            if not df_projetado.empty:
                st.subheader("üìã Valores Projetados")
                st.dataframe(df_projetado[['Ano', 'PIB_per_capita']].round(2))
    
    # An√°lise de Sensibilidade
    st.subheader("üéØ An√°lise de Sensibilidade")
    st.info("üí° Analise como mudan√ßas em indicadores espec√≠ficos afetam as proje√ß√µes do PIB per capita.")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        pais_sensibilidade = st.selectbox("Pa√≠s para an√°lise:", 
                                        df_processado['Pa√≠s'].unique(), 
                                        key="pais_sens")
    
    with col2:
        # Indicadores dispon√≠veis (excluindo PIB per capita)
        indicadores_disponiveis = [col for col in df_processado.columns 
                                 if col not in ['Pa√≠s', 'Ano', 'PIB_per_capita']]
        indicador_choque = st.selectbox("Indicador para variar:", indicadores_disponiveis)
    
    with col3:
        variacao_pct = st.slider("Varia√ß√£o percentual:", -50, 50, 10)
    
    if st.button("üî¨ Executar An√°lise de Sensibilidade"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Cen√°rio Base:**")
            with st.spinner("Calculando cen√°rio base..."):
                projecao_base = gerar_projecao_com_cenario(
                    pais_sensibilidade, melhor_modelo, df_processado, 
                    ano_projecao, usar_log=usar_log
                )
        
        with col2:
            st.write(f"**Cen√°rio com {indicador_choque} variando {variacao_pct:+}%:**")
            with st.spinner("Calculando cen√°rio alternativo..."):
                projecao_cenario = gerar_projecao_com_cenario(
                    pais_sensibilidade, melhor_modelo, df_processado, 
                    ano_projecao, indicador_choque, variacao_pct, usar_log=usar_log
                )
        
        if projecao_base is not None and projecao_cenario is not None:
            # Gr√°fico comparativo
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=projecao_base['Ano'], 
                y=projecao_base['PIB_per_capita'],
                mode='lines+markers',
                name='Cen√°rio Base',
                line=dict(color='blue')
            ))
            
            fig.add_trace(go.Scatter(
                x=projecao_cenario['Ano'], 
                y=projecao_cenario['PIB_per_capita'],
                mode='lines+markers',
                name=f'{indicador_choque} {variacao_pct:+}%',
                line=dict(color='red', dash='dash')
            ))
            
            # Marcar divis√£o hist√≥rica
            ultimo_ano_hist = df_processado[df_processado['Pa√≠s'] == pais_sensibilidade]['Ano'].max()
            fig.add_vline(x=ultimo_ano_hist, line_dash="dot", line_color="gray")
            
            fig.update_layout(
                title=f'An√°lise de Sensibilidade - {pais_sensibilidade}',
                xaxis_title='Ano',
                yaxis_title='PIB per Capita (US$)',
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Calcular impacto
            anos_projecao = projecao_base[projecao_base['Ano'] > ultimo_ano_hist]['Ano'].values
            if len(anos_projecao) > 0:
                pib_base_final = projecao_base[projecao_base['Ano'] == anos_projecao[-1]]['PIB_per_capita'].iloc[0]
                pib_cenario_final = projecao_cenario[projecao_cenario['Ano'] == anos_projecao[-1]]['PIB_per_capita'].iloc[0]
                impacto_pct = ((pib_cenario_final - pib_base_final) / pib_base_final) * 100
                
                st.metric(
                    f"Impacto no PIB per capita em {anos_projecao[-1]}:",
                    f"{impacto_pct:+.2f}%",
                    f"US$ {pib_cenario_final - pib_base_final:+,.0f}"
                )
    
    # An√°lise Detalhada da Previs√£o (SHAP para predi√ß√µes espec√≠ficas)
    if melhor_modelo_nome in ['XGBoost', 'Random Forest']:
        st.subheader("üî¨ An√°lise Detalhada da Previs√£o")
        st.info("üí° Veja como cada indicador contribui para uma previs√£o espec√≠fica.")
        
        col1, col2 = st.columns(2)
        with col1:
            pais_shap = st.selectbox("Pa√≠s para an√°lise detalhada:", 
                                   df_processado['Pa√≠s'].unique(), 
                                   key="pais_shap")
        with col2:
            anos_disponiveis = df_model.reset_index()[df_model.reset_index()['Pa√≠s'] == pais_shap]['Ano'].values
            if len(anos_disponiveis) > 0:
                ano_shap = st.selectbox("Ano:", sorted(anos_disponiveis, reverse=True)[:5])
            else:
                st.warning("Sem dados dispon√≠veis para este pa√≠s.")
                ano_shap = None
        
        if ano_shap is not None and st.button("üîç Analisar Previs√£o"):
            try:
                # Encontrar a observa√ß√£o espec√≠fica
                obs_especifica = df_model.reset_index()
                obs_especifica = obs_especifica[
                    (obs_especifica['Pa√≠s'] == pais_shap) & 
                    (obs_especifica['Ano'] == ano_shap)
                ]
                
                if not obs_especifica.empty:
                    # Preparar dados para SHAP
                    feature_cols = [col for col in obs_especifica.columns 
                                  if col not in ['Pa√≠s', 'Ano', 'PIB_per_capita']]
                    X_obs = obs_especifica[feature_cols].values
                    
                    # Calcular SHAP values
                    explainer = shap.TreeExplainer(melhor_modelo)
                    shap_values = explainer.shap_values(X_obs)
                    
                    # Criar gr√°fico waterfall
                    import matplotlib.pyplot as plt
                    fig, ax = plt.subplots(figsize=(12, 8))
                    
                    shap.waterfall_plot(
                        explainer.expected_value, 
                        shap_values[0], 
                        X_obs[0], 
                        feature_names=feature_cols,
                        show=False
                    )
                    
                    st.pyplot(fig)
                    plt.close()
                    
                    # Mostrar valores reais vs preditos
                    pib_real = obs_especifica['PIB_per_capita'].iloc[0]
                    pib_pred = melhor_modelo.predict(X_obs)[0]
                    
                    if usar_log:
                        pib_pred = np.expm1(pib_pred)
                        pib_real = np.expm1(pib_real) if pib_real > 0 else pib_real
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("PIB Real", f"US$ {pib_real:,.0f}")
                    with col2:
                        st.metric("PIB Predito", f"US$ {pib_pred:,.0f}")
                    with col3:
                        erro = abs(pib_real - pib_pred) / pib_real * 100
                        st.metric("Erro (%)", f"{erro:.2f}%")
                
            except Exception as e:
                st.error(f"‚ùå Erro na an√°lise SHAP: {str(e)}")
    
    # Exportar dados
    st.subheader("üíæ Exportar Dados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üì• Baixar Dados Processados"):
            csv = df_processado.to_csv(index=False)
            st.download_button(
                label="üíæ Download CSV",
                data=csv,
                file_name=f"dados_economicos_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
    
    with col2:
        if st.button("üìä Baixar Resultados dos Modelos"):
            resultados_export = pd.DataFrame({
                'Modelo': list(resultados.keys()),
                'MAE': [res['mae'] for res in resultados.values()],
                'RMSE': [res['rmse'] for res in resultados.values()],
                'R2': [res['r2'] for res in resultados.values()]
            })
            csv = resultados_export.to_csv(index=False)
            st.download_button(
                label="üíæ Download Resultados",
                data=csv,
                file_name=f"resultados_modelos_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
    
    # Informa√ß√µes t√©cnicas
    with st.expander("‚ÑπÔ∏è Informa√ß√µes T√©cnicas"):
        st.markdown("""
        ### üîß Metodologia
        
        **Processamento de Dados:**
        - Estrat√©gia de imputa√ß√£o multin√≠vel para maximizar reten√ß√£o de pa√≠ses
        - Interpola√ß√£o linear ‚Üí Forward-fill ‚Üí Backward-fill ‚Üí Preenchimento com zero
        - Engenharia de features com vari√°veis defasadas (lag-1)
        
        **Modelos Utilizados:**
        - **XGBoost**: Gradient boosting otimizado para dados tabulares
        - **Random Forest**: Ensemble de √°rvores de decis√£o
        - **Regress√£o Linear**: Modelo baseline linear
        
        **Transforma√ß√µes:**
        - Op√ß√£o de transforma√ß√£o logar√≠tmica para vari√°veis monet√°rias
        - Normaliza√ß√£o autom√°tica para melhor performance dos modelos
        
        **Explicabilidade:**
        - An√°lise SHAP para interpreta√ß√£o de modelos
        - An√°lise de sensibilidade para cen√°rios alternativos
        
        **Fonte dos Dados:**
        - Banco Mundial (World Bank Open Data)
        - Cache local para evitar limita√ß√µes de API
        """)
        
        st.markdown("""
        ### üìà Indicadores Utilizados
        
        **Econ√¥micos:**
        - PIB per capita, Forma√ß√£o Bruta de Capital, Exporta√ß√µes
        - Consumo das Fam√≠lias, Investimento Estrangeiro Direto
        - Renda Nacional Bruta per capita
        
        **Sociais:**
        - Alfabetiza√ß√£o, Expectativa de Vida, Acesso √† Eletricidade
        - Cobertura de Internet, Acesso √† √Ågua Pot√°vel
        
        **Governan√ßa:**
        - Qualidade Regulat√≥ria, Gastos Governamentais
        - D√≠vida do Governo Central, Gastos Militares
        
        **Mercado de Trabalho:**
        - Taxa de Desemprego, Participa√ß√£o na For√ßa de Trabalho
        - Conclus√£o do Ensino Prim√°rio
        """)

if __name__ == "__main__":
    main()

# =============================================================================
# C√ìDIGO DA RIQUEZA - VERS√ÉO MELHORADA
# Previs√£o de PIB per capita usando Machine Learning
# =============================================================================

import streamlit as st
import pandas as pd
import numpy as np
import wbdata
import plotly.graph_objects as go
import plotly.express as px
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURA√á√ïES E INDICADORES EXPANDIDOS
# =============================================================================

INDICADORES = {
    # Indicadores Originais
    "NY.GDP.PCAP.KD": "PIB_per_capita",
    "NE.GDI.FTOT.CD": "Formacao_Bruta_Capital", 
    "SE.ADT.1524.LT.ZS": "Alfabetizacao_Jovens",
    "SL.TLF.CACT.ZS": "Participacao_Forca_Trabalho",
    "IT.NET.USER.ZS": "Cobertura_Internet",
    "NE.EXP.GNFS.CD": "Valor_Exportacoes",
    "NY.GNP.PCAP.CD": "Renda_Nacional_Bruta_per_Capita",
    "EG.ELC.ACCS.ZS": "Acesso_Eletricidade",
    "SI.POV.GINI": "Gini",
    "SL.UEM.TOTL.ZS": "Desemprego",
    "SE.PRM.CMPT.ZS": "Conclusao_Ensino_Primario",
    "NE.CON.PRVT.CD": "Consumo_Familias",
    "SH.H2O.BASW.ZS": "Cobertura_Agua_Potavel",
    # Novos Indicadores
    "FP.CPI.TOTL.ZG": "Inflacao_Anual_Consumidor",
    "BX.KLT.DINV.CD.WD": "Investimento_Estrangeiro_Direto",
    "SP.DYN.LE00.IN": "Expectativa_de_Vida",
    "SE.XPD.TOTL.GD.ZS": "Gastos_Governamentais_Educacao",
    "GC.DOD.TOTL.GD.ZS": "Divida_Governo_Central_perc_PIB",
    "IQ.CPA.BREG.XQ": "Qualidade_Regulatoria",
    "MS.MIL.XPND.GD.ZS": "Gastos_Militares_perc_PIB",
    "TX.VAL.TECH.MF.ZS": "Exportacoes_Alta_Tecnologia_perc"
}

# =============================================================================
# FUN√á√ïES DE CARREGAMENTO E PROCESSAMENTO DE DADOS
# =============================================================================

@st.cache_data
def carregar_dados_banco_mundial(paises, anos):
    """
    Carrega dados do Banco Mundial com cache local para evitar erro 429.
    """
    cache_file = "dados_banco_mundial.csv"
    
    try:
        # Tenta carregar dados do cache local
        st.info("üîÑ Tentando carregar dados do cache local...")
        df_cached = pd.read_csv(cache_file)
        
        # Verifica se os dados em cache cobrem os pa√≠ses e anos solicitados
        df_cached['date'] = pd.to_numeric(df_cached['date'])
        paises_cache = df_cached['country'].unique()
        anos_cache = df_cached['date'].unique()
        
        # Filtra pelos pa√≠ses e anos solicitados
        df_filtered = df_cached[
            (df_cached['country'].isin(paises)) & 
            (df_cached['date'].isin(anos))
        ]
        
        if len(df_filtered) > 0:
            st.success("‚úÖ Dados carregados do cache!")
            return df_cached
        else:
            st.warning("‚ö†Ô∏è Cache insuficiente, baixando da API...")
            raise FileNotFoundError("Cache insuficiente")
            
    except (FileNotFoundError, pd.errors.EmptyDataError):
        # Se n√£o h√° cache, baixa da API
        st.info("üåê Baixando dados do Banco Mundial...")
        
        try:
            # Baixa dados da API
            df_raw = wbdata.get_dataframe(
                INDICADORES,
                country=paises,
                data_date=anos
            )
            
            if df_raw is not None and not df_raw.empty:
                # Salva no cache para uso futuro
                df_raw.reset_index().to_csv(cache_file, index=False)
                st.success("‚úÖ Dados baixados e salvos no cache!")
                return df_raw
            else:
                st.error("‚ùå Erro ao baixar dados da API.")
                return None
                
        except Exception as e:
            st.error(f"‚ùå Erro ao acessar API: {str(e)}")
            return None

def processar_dados(df_raw):
    """
    Processa e limpa os dados com uma estrat√©gia de imputa√ß√£o robusta
    para maximizar a reten√ß√£o de pa√≠ses.
    """
    if df_raw is None:
        return None, None
    
    df = df_raw.copy().reset_index()
    
    # Renomear colunas
    if 'country' in df.columns:
        df.rename(columns={'country': 'Pa√≠s'}, inplace=True)
    if 'date' in df.columns:
        df.rename(columns={'date': 'Ano'}, inplace=True)
        df['Ano'] = pd.to_numeric(df['Ano'])
    
    if 'Pa√≠s' not in df.columns or 'Ano' not in df.columns:
        st.error("As colunas 'Pa√≠s' e/ou 'Ano' n√£o est√£o dispon√≠veis.")
        return None, None
    
    df = df.sort_values(by=['Pa√≠s', 'Ano'])
    
    # --- ESTRAT√âGIA DE IMPUTA√á√ÉO MULTIN√çVEL ---
    # Para cada pa√≠s, aplicamos uma s√©rie de preenchimentos.
    # Esta √© a etapa mais importante para n√£o perder pa√≠ses.
    indicadores_a_processar = [col for col in df.columns if col not in ['Pa√≠s', 'Ano']]
    
    df_processado = df.groupby('Pa√≠s', group_keys=False).apply(
        lambda group: group.set_index('Ano')[indicadores_a_processar]
                           .interpolate(method='linear', limit_direction='both') # 1. Interpola√ß√£o linear
                           .ffill()                                               # 2. Forward-fill
                           .bfill()                                               # 3. Backward-fill
    ).reset_index()
    
    # Como √∫ltimo recurso, se um indicador inteiro para um pa√≠s for nulo, preenchemos com 0.
    df_processado.fillna(0, inplace=True)
    
    # Relat√≥rio de qualidade dos dados
    dados_faltantes_antes = df_raw.isnull().sum().sum()
    dados_imputados = dados_faltantes_antes - df_processado.isnull().sum().sum()
    print(f"Relat√≥rio de Qualidade: {dados_imputados} de {dados_faltantes_antes} pontos de dados faltantes foram imputados.")
    
    # --- Prepara√ß√£o para o Modelo ---
    df_model = df_processado.copy().set_index(['Pa√≠s', 'Ano'])
    
    # Remove a vari√°vel alvo dos preditores
    if 'PIB_per_capita' in df_model.columns:
        target = df_model['PIB_per_capita']
        predictors_df = df_model.drop(columns=['PIB_per_capita'])
    else:
        st.error("A coluna 'PIB_per_capita' n√£o foi encontrada ap√≥s o processamento.")
        return None, None
    
    # Engenharia de vari√°veis (lags)
    for var in predictors_df.columns:
        df_model[f'{var}_lag1'] = predictors_df.groupby('Pa√≠s')[var].shift(1)
    
    # Ap√≥s criar os lags, a primeira linha de cada pa√≠s ter√° NaNs. Vamos remov√™-los.
    # Este √© o √∫nico dropna() necess√°rio e seguro.
    df_model = df_model.dropna()
    
    return df_processado, df_model

def mostrar_relatorio_qualidade(df_raw):
    """
    Mostra relat√≥rio de qualidade dos dados.
    """
    st.subheader("‚úÖ Qualidade e Cobertura dos Dados")
    
    if df_raw is not None:
        # Calcular a porcentagem de dados originais que eram nulos para cada pa√≠s
        df_raw_check = df_raw.reset_index()
        missing_data_report = df_raw_check.groupby('country').apply(
            lambda x: x.isnull().sum().sum() / (len(x.columns) * len(x))
        ).sort_values(ascending=False)
        
        missing_data_report = missing_data_report[missing_data_report > 0] * 100
        
        if not missing_data_report.empty:
            st.warning("‚ö†Ô∏è Aten√ß√£o: Os pa√≠ses a seguir exigiram preenchimento significativo de dados faltantes, o que pode afetar a precis√£o das proje√ß√µes. Os dados foram preenchidos usando interpola√ß√£o e outras t√©cnicas.")
            
            df_report = pd.DataFrame({
                'Pa√≠s': missing_data_report.index, 
                '% de Dados Faltantes (Original)': missing_data_report.values.round(2)
            })
            
            st.dataframe(df_report.head(10)) # Mostra os 10 piores
        else:
            st.success("‚úÖ Todos os pa√≠ses selecionados possuem boa cobertura de dados.")

# =============================================================================
# FUN√á√ïES DE MODELAGEM E PREVIS√ÉO
# =============================================================================

def treinar_modelos(df_model, usar_log=False):
    """
    Treina diferentes modelos de machine learning.
    """
    if df_model is None or df_model.empty:
        return None, None, None
    
    # Preparar dados
    y = df_model['PIB_per_capita'].values
    X = df_model.drop(columns=['PIB_per_capita']).values
    
    # Aplicar transforma√ß√£o logar√≠tmica se solicitado
    if usar_log:
        y = np.log1p(y)  # log(1 + y) para lidar com valores zero
    
    # Modelos
    modelos = {
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'Gradient Boosting': GradientBoostingRegressor(random_state=42),
        'Ridge Regression': Ridge(alpha=1.0)
    }
    
    # Valida√ß√£o cruzada temporal
    tscv = TimeSeriesSplit(n_splits=5)
    resultados = {}
    
    for nome, modelo in modelos.items():
        scores = cross_val_score(modelo, X, y, cv=tscv, scoring='r2')
        resultados[nome] = {
            'modelo': modelo,
            'r2_medio': scores.mean(),
            'r2_std': scores.std()
        }
    
    # Encontrar melhor modelo
    melhor_nome = max(resultados.keys(), key=lambda k: resultados[k]['r2_medio'])
    melhor_modelo = resultados[melhor_nome]['modelo']
    
    # Treinar modelo final com todos os dados
    melhor_modelo.fit(X, y)
    
    return melhor_modelo, resultados, melhor_nome

def gerar_projecao_com_cenario(pais, modelo, df_processado, ano_final, 
                               indicador_para_chocar=None, variacao_percentual=0):
    """
    Gera proje√ß√£o com cen√°rio espec√≠fico para an√°lise de sensibilidade.
    """
    # Preparar dados do pa√≠s
    df_pais = df_processado[df_processado['Pa√≠s'] == pais].copy()
    if df_pais.empty:
        return None
    
    df_pais = df_pais.sort_values('Ano')
    ultimo_ano = df_pais['Ano'].max()
    
    # Se o ano final j√° existe nos dados, usar dados hist√≥ricos
    if ano_final <= ultimo_ano:
        return df_pais[df_pais['Ano'] <= ano_final]
    
    projecoes = []
    dados_base = df_pais.copy()
    
    for ano in range(ultimo_ano + 1, ano_final + 1):
        # Pegar dados do ano anterior
        dados_anterior = dados_base[dados_base['Ano'] == (ano - 1)].iloc[0]
        
        # Preparar features para predi√ß√£o
        features_dict = {}
        feature_cols = [col for col in dados_anterior.index if col not in ['Pa√≠s', 'Ano', 'PIB_per_capita']]
        
        for col in feature_cols:
            if col.endswith('_lag1'):
                # Para vari√°veis lag, usar o valor do ano anterior
                base_var = col.replace('_lag1', '')
                if base_var in dados_anterior.index:
                    features_dict[col] = dados_anterior[base_var]
                else:
                    features_dict[col] = dados_anterior[col]
            else:
                # Para outras vari√°veis, aplicar cen√°rio se necess√°rio
                valor_base = dados_anterior[col]
                
                if indicador_para_chocar and col == indicador_para_chocar:
                    # Aplicar varia√ß√£o percentual PERSISTENTE
                    valor_base = valor_base * (1 + variacao_percentual / 100)
                
                features_dict[col] = valor_base
        
        # Criar array de features na ordem correta
        feature_names = modelo.feature_names_in_ if hasattr(modelo, 'feature_names_in_') else list(features_dict.keys())
        X_pred = np.array([features_dict.get(name, 0) for name in feature_names]).reshape(1, -1)
        
        # Fazer predi√ß√£o
        pib_pred = modelo.predict(X_pred)[0]
        
        # Criar nova linha
        nova_linha = dados_anterior.copy()
        nova_linha['Ano'] = ano
        nova_linha['PIB_per_capita'] = pib_pred
        
        # Atualizar indicadores com cen√°rio para pr√≥xima itera√ß√£o
        if indicador_para_chocar and indicador_para_chocar in nova_linha.index:
            nova_linha[indicador_para_chocar] = nova_linha[indicador_para_chocar] * (1 + variacao_percentual / 100)
        
        # Adicionar √† base de dados para pr√≥xima itera√ß√£o
        dados_base = pd.concat([dados_base, nova_linha.to_frame().T], ignore_index=True)
        projecoes.append(nova_linha)
    
    # Combinar hist√≥rico com proje√ß√µes
    if projecoes:
        df_projecoes = pd.DataFrame(projecoes)
        resultado = pd.concat([df_pais, df_projecoes], ignore_index=True)
    else:
        resultado = df_pais
    
    return resultado.sort_values('Ano')

# =============================================================================
# SE√á√ïES DA INTERFACE
# =============================================================================

def secao_analise_sensibilidade(df_processado, melhor_modelo, ano_projecao):
    """
    Se√ß√£o corrigida da an√°lise de sensibilidade.
    """
    st.subheader("üéØ An√°lise de Sensibilidade")
    st.info("üí° O PIB per capita √© o alvo da previs√£o e n√£o pode ser selecionado para manipula√ß√£o.")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        pais_sensibilidade = st.selectbox("Pa√≠s para an√°lise:", 
                                        df_processado['Pa√≠s'].unique(), 
                                        key="pais_sens")
    
    with col2:
        # Indicadores dispon√≠veis (excluindo PIB per capita)
        indicadores_disponiveis = [col for col in df_processado.columns 
                                 if col not in ['Pa√≠s', 'Ano', 'PIB_per_capita']]
        indicador_choque = st.selectbox("Indicador para variar:", indicadores_disponiveis)
    
    with col3:
        variacao_pct = st.slider("Varia√ß√£o percentual:", -50, 50, 10)
    
    if st.button("üî¨ Executar An√°lise de Sensibilidade"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Cen√°rio Base:**")
            projecao_base = gerar_projecao_com_cenario(
                pais_sensibilidade, melhor_modelo, df_processado, ano_projecao
            )
        
        with col2:
            st.write(f"**Cen√°rio com {indicador_choque} variando {variacao_pct:+}%:**")
            projecao_cenario = gerar_projecao_com_cenario(
                pais_sensibilidade, melhor_modelo, df_processado, 
                ano_projecao, indicador_choque, variacao_pct
            )
        
        if projecao_base is not None and projecao_cenario is not None:
            # Gr√°fico comparativo
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=projecao_base['Ano'], 
                y=projecao_base['PIB_per_capita'],
                mode='lines+markers',
                name='Cen√°rio Base',
                line=dict(color='blue')
            ))
            
            fig.add_trace(go.Scatter(
                x=projecao_cenario['Ano'], 
                y=projecao_cenario['PIB_per_capita'],
                mode='lines+markers',
                name=f'{indicador_choque} {variacao_pct:+}%',
                line=dict(color='red', dash='dash')
            ))
            
            # Marcar divis√£o hist√≥rica
            ultimo_ano_hist = df_processado[df_processado['Pa√≠s'] == pais_sensibilidade]['Ano'].max()
            fig.add_vline(x=ultimo_ano_hist, line_dash="dot", line_color="gray")
            
            fig.update_layout(
                title=f'An√°lise de Sensibilidade - {pais_sensibilidade}',
                xaxis_title='Ano',
                yaxis_title='PIB per Capita (US$)',
                hovermode='x unified'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Calcular impacto
            anos_projecao = projecao_base[projecao_base['Ano'] > ultimo_ano_hist]['Ano'].values
            if len(anos_projecao) > 0:
                pib_base_final = projecao_base[projecao_base['Ano'] == anos_projecao[-1]]['PIB_per_capita'].iloc[0]
                pib_cenario_final = projecao_cenario[projecao_cenario['Ano'] == anos_projecao[-1]]['PIB_per_capita'].iloc[0]
                impacto_pct = ((pib_cenario_final - pib_base_final) / pib_base_final) * 100
                
                st.metric(
                    f"Impacto no PIB per capita em {anos_projecao[-1]}:",
                    f"{impacto_pct:+.2f}%",
                    f"US$ {pib_cenario_final - pib_base_final:+,.0f}"
                )

# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================

def main():
    st.set_page_config(
        page_title="üí∞ C√≥digo da Riqueza",
        page_icon="üí∞",
        layout="wide"
    )
    
    st.title("üí∞ C√≥digo da Riqueza")
    st.subtitle("Previs√£o de PIB per capita usando Machine Learning")
    
    # Sidebar
    st.sidebar.header("‚öôÔ∏è Configura√ß√µes")
    
    # Sele√ß√£o de pa√≠ses
    paises_sugeridos = ['BRA', 'USA', 'CHN', 'DEU', 'JPN', 'GBR', 'FRA', 'IND', 'ITA', 'CAN']
    paises_selecionados = st.sidebar.multiselect(
        "Selecione os pa√≠ses:",
        options=paises_sugeridos,
        default=['BRA', 'USA', 'CHN']
    )
    
    # Per√≠odo de an√°lise
    ano_inicio = st.sidebar.slider("Ano inicial:", 2000, 2020, 2010)
    ano_fim = st.sidebar.slider("Ano final:", 2015, 2023, 2022)
    
    # Ano de proje√ß√£o
    ano_projecao = st.sidebar.slider("Ano para proje√ß√£o:", 2024, 2035, 2030)
    
    # Op√ß√£o de transforma√ß√£o logar√≠tmica
    usar_log = st.sidebar.checkbox("Usar transforma√ß√£o logar√≠tmica para melhorar o modelo")
    
    if not paises_selecionados:
        st.warning("‚ö†Ô∏è Selecione pelo menos um pa√≠s para continuar.")
        return
    
    # Carregar dados
    anos = list(range(ano_inicio, ano_fim + 1))
    
    with st.spinner("Carregando dados..."):
        df_raw = carregar_dados_banco_mundial(paises_selecionados, anos)
    
    if df_raw is None:
        st.error("‚ùå N√£o foi poss√≠vel carregar os dados. Tente novamente mais tarde.")
        return
    
    # Mostrar relat√≥rio de qualidade
    mostrar_relatorio_qualidade(df_raw)
    
    # Processar dados
    with st.spinner("Processando dados..."):
        df_processado, df_model = processar_dados(df_raw)
    
    if df_processado is None or df_model is None:
        st.error("‚ùå Erro no processamento dos dados.")
        return
    
    # Treinar modelos
    with st.spinner("Treinando modelos..."):
        melhor_modelo, resultados, melhor_nome = treinar_modelos(df_model, usar_log)
    
    if melhor_modelo is None:
        st.error("‚ùå Erro no treinamento dos modelos.")
        return
    
    # Mostrar resultados dos modelos
    st.subheader("üéØ Desempenho dos Modelos")
    col1, col2, col3 = st.columns(3)
    
    for i, (nome, resultado) in enumerate(resultados.items()):
        with [col1, col2, col3][i]:
            destaque = nome == melhor_nome
            st.metric(
                label=f"{'üèÜ ' if destaque else ''}{nome}",
                value=f"{resultado['r2_medio']:.3f}",
                delta=f"¬±{resultado['r2_std']:.3f}"
            )
    
    st.success(f"‚úÖ Melhor modelo: **{melhor_nome}** (R¬≤ = {resultados[melhor_nome]['r2_medio']:.3f})")
    
    # Gr√°ficos principais
    st.subheader("üìä An√°lise Explorat√≥ria")
    
    # Gr√°fico de PIB per capita ao longo do tempo
    fig = px.line(
        df_processado, 
        x='Ano', 
        y='PIB_per_capita', 
        color='Pa√≠s',
        title='Evolu√ß√£o do PIB per capita'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Proje√ß√µes
    st.subheader("üîÆ Proje√ß√µes para o Futuro")
    
    for pais in paises_selecionados:
        projecao = gerar_projecao_com_cenario(pais, melhor_modelo, df_processado, ano_projecao)
        
        if projecao is not None:
            fig = go.Figure()
            
            # Dados hist√≥ricos
            dados_hist = projecao[projecao['Ano'] <= ano_fim]
            fig.add_trace(go.Scatter(
                x=dados_hist['Ano'],
                y=dados_hist['PIB_per_capita'],
                mode='lines+markers',
                name='Hist√≥rico',
                line=dict(color='blue')
            ))
            
            # Proje√ß√µes
            dados_proj = projecao[projecao['Ano'] > ano_fim]
            if not dados_proj.empty:
                fig.add_trace(go.Scatter(
                    x=dados_proj['Ano'],
                    y=dados_proj['PIB_per_capita'],
                    mode='lines+markers',
                    name='Proje√ß√£o',
                    line=dict(color='red', dash='dash')
                ))
            
            fig.add_vline(x=ano_fim, line_dash="dot", line_color="gray")
            fig.update_layout(
                title=f'Proje√ß√£o PIB per capita - {pais}',
                xaxis_title='Ano',
                yaxis_title='PIB per Capita (US$)'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # An√°lise de sensibilidade
    secao_analise_sensibilidade(df_processado, melhor_modelo, ano_projecao)
    
    # Mostrar dados processados
    with st.expander("üìã Ver dados processados"):
        st.dataframe(df_processado)

if __name__ == "__main__":
    main()

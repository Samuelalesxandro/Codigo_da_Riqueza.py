import pandas as pd
import wbdata
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBRegressor
from sklearn.metrics import r2_score
from datetime import datetime
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import streamlit as st
import warnings
import os
import time
import requests
from typing import Optional, Dict, List, Tuple
warnings.filterwarnings('ignore')

# --- CONFIGURA√á√ÉO AVAN√áADA DO PROJETO ---
INDICADORES = {
    # Indicadores Econ√¥micos Fundamentais
    "NY.GDP.PCAP.KD": "PIB_per_capita",
    "NE.GDI.FTOT.CD": "Formacao_Bruta_Capital", 
    "NY.GNP.PCAP.CD": "Renda_Nacional_Bruta_per_Capita",
    "NE.EXP.GNFS.CD": "Valor_Exportacoes",
    "NE.CON.PRVT.CD": "Consumo_Familias",
    "BX.KLT.DINV.CD.WD": "Investimento_Estrangeiro_Direto",
    "FP.CPI.TOTL.ZG": "Inflacao_Anual_Consumidor",
    "GC.DOD.TOTL.GD.ZS": "Divida_Governo_Central_perc_PIB",
    
    # Indicadores de Capital Humano
    "SE.ADT.1524.LT.ZS": "Alfabetizacao_Jovens",
    "SE.PRM.CMPT.ZS": "Conclusao_Ensino_Primario",
    "SE.XPD.TOTL.GD.ZS": "Gastos_Governamentais_Educacao",
    "SP.DYN.LE00.IN": "Expectativa_de_Vida",
    
    # Indicadores de Trabalho e Produtividade
    "SL.TLF.CACT.ZS": "Participacao_Forca_Trabalho",
    "SL.UEM.TOTL.ZS": "Desemprego",
    
    # Indicadores de Infraestrutura e Tecnologia
    "IT.NET.USER.ZS": "Cobertura_Internet",
    "EG.ELC.ACCS.ZS": "Acesso_Eletricidade",
    "SH.H2O.BASW.ZS": "Cobertura_Agua_Potavel",
    "TX.VAL.TECH.MF.ZS": "Exportacoes_Alta_Tecnologia_perc",
    
    # Indicadores de Governan√ßa e Distribui√ß√£o
    "SI.POV.GINI": "Gini",
    "IQ.CPA.BREG.XQ": "Qualidade_Regulatoria",
    "MS.MIL.XPND.GD.ZS": "Gastos_Militares_perc_PIB"
}

# Grupos de pa√≠ses para an√°lise comparativa
ZONA_DO_EURO = ['DEU', 'FRA', 'ITA', 'ESP', 'PRT', 'GRC', 'IRL', 'NLD', 'AUT', 'BEL']
BRICS = ['BRA', 'RUS', 'IND', 'CHN', 'ZAF', 'EGY', 'ETH', 'IRN', 'SAU', 'ARE']      
PAISES_SUL_AMERICA = ['BRA', 'ARG', 'CHL', 'COL', 'PER', 'ECU', 'VEN', 'BOL', 'PRY', 'URY']
PAISES_SUDESTE_ASIATICO = ['IDN', 'THA', 'VNM', 'PHL', 'MYS', 'SGP', 'MMR', 'KHM', 'LAO', 'BRN']
TIGRES_ASIATICOS = ['KOR', 'TWN', 'HKG', 'SGP']
ECONOMIAS_AVANCADAS = ['USA', 'JPN', 'GBR', 'CAN', 'AUS', 'CHE', 'NOR', 'SWE', 'DNK']

TODOS_PAISES = list(set(
    PAISES_SUL_AMERICA + PAISES_SUDESTE_ASIATICO + BRICS + 
    ZONA_DO_EURO + TIGRES_ASIATICOS + ECONOMIAS_AVANCADAS
))

DATA_INICIO = datetime(1990, 1, 1)
DATA_FIM = datetime(2025, 6, 30)

# Cache global para evitar m√∫ltiplas requisi√ß√µes
_cached_data = None
_cached_models = None
_cache_timestamp = None
CACHE_DURATION = 3600  # 1 hora

class WorldBankDataLoader:
    """Classe para carregar dados do Banco Mundial com sistema robusto de cache e rate limiting"""
    
    def __init__(self):
        self.cache_file = "dados_banco_mundial_cache.csv"
        self.metadata_file = "cache_metadata.json"
        self.max_retries = 3
        self.base_delay = 2
        
    def load_with_cache_and_retry(self) -> Optional[pd.DataFrame]:
        """Carrega dados com sistema de cache local e retry autom√°tico"""
        global _cached_data, _cache_timestamp
        
        # Verificar cache em mem√≥ria
        if _cached_data is not None and _cache_timestamp is not None:
            if time.time() - _cache_timestamp < CACHE_DURATION:
                st.info("üìã Dados carregados do cache em mem√≥ria")
                return _cached_data
        
        # Tentar carregar do cache local
        try:
            if self._is_cache_valid():
                st.info("üíæ Carregando dados do cache local...")
                df_cached = pd.read_csv(self.cache_file)
                # Verificar se tem as colunas corretas
                if 'country' in df_cached.columns and 'date' in df_cached.columns:
                    df_cached = df_cached.set_index(['country', 'date'])
                    _cached_data = df_cached
                    _cache_timestamp = time.time()
                    st.success("‚úÖ Dados carregados do cache local com sucesso!")
                    return _cached_data
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erro ao ler cache local: {e}")
        
        # Baixar dados da API com retry
        return self._download_with_retry()
    
    def _is_cache_valid(self) -> bool:
        """Verifica se o cache local √© v√°lido (n√£o mais que 24 horas)"""
        if not os.path.exists(self.cache_file):
            return False
        
        file_age = time.time() - os.path.getmtime(self.cache_file)
        return file_age < 86400  # 24 horas
    
    def _download_with_retry(self) -> Optional[pd.DataFrame]:
        """Baixa dados da API com sistema de retry exponencial"""
        global _cached_data, _cache_timestamp
        
        for attempt in range(self.max_retries):
            try:
                delay = self.base_delay * (2 ** attempt)
                if attempt > 0:
                    st.warning(f"üîÑ Tentativa {attempt + 1}/{self.max_retries} ap√≥s {delay}s...")
                    time.sleep(delay)
                
                st.info("üåê Baixando dados do Banco Mundial...")
                df_raw = wbdata.get_dataframe(
                    indicators=INDICADORES, 
                    country=TODOS_PAISES, 
                    date=(DATA_INICIO, DATA_FIM)
                )
                
                # Salvar no cache
                df_to_save = df_raw.reset_index()
                df_to_save.to_csv(self.cache_file, index=False)
                
                _cached_data = df_raw
                _cache_timestamp = time.time()
                
                st.success("‚úÖ Dados baixados e salvos no cache com sucesso!")
                return _cached_data
                
            except Exception as e:
                if "429" in str(e) or "rate limit" in str(e).lower():
                    st.error(f"üö´ Rate limit atingido (Tentativa {attempt + 1}): {e}")
                    if attempt < self.max_retries - 1:
                        continue
                else:
                    st.error(f"‚ùå Erro na API (Tentativa {attempt + 1}): {e}")
                    
                if attempt == self.max_retries - 1:
                    st.error("‚ùå Falha ap√≥s todas as tentativas. Verifique sua conex√£o e tente novamente mais tarde.")
                    return None
        
        return None

class DataProcessor:
    """Classe para processar e limpar os dados com estrat√©gias avan√ßadas de imputa√ß√£o"""
    
    def __init__(self):
        self.quality_report = {}
    
    def process_data(self, df_raw: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        """Processa os dados com estrat√©gia multin√≠vel de imputa√ß√£o"""
        if df_raw is None:
            return None, None
            
        df = df_raw.copy().reset_index()
        
        # Padronizar nomes das colunas PRIMEIRO
        df = self._standardize_columns(df)
        
        # Verificar se as colunas foram padronizadas corretamente
        if 'Pa√≠s' not in df.columns or 'Ano' not in df.columns:
            st.error(f"‚ùå Erro na padroniza√ß√£o das colunas. Colunas dispon√≠veis: {list(df.columns)}")
            return None, None
        
        df = df.sort_values(by=['Pa√≠s', 'Ano'])
        
        # Relat√≥rio de qualidade inicial
        self._generate_quality_report(df, "inicial")
        
        # Aplicar estrat√©gia de imputa√ß√£o multin√≠vel
        df_processed = self._apply_multilevel_imputation(df)
        
        # Relat√≥rio de qualidade final
        self._generate_quality_report(df_processed, "final")
        
        # Preparar dados para modelagem
        df_model = self._prepare_for_modeling(df_processed)
        
        return df_processed, df_model
    
    def _standardize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """Padroniza nomes das colunas"""
        df = df.copy()
        
        # Renomear colunas do √≠ndice
        if 'country' in df.columns:
            df.rename(columns={'country': 'Pa√≠s'}, inplace=True)
        if 'date' in df.columns:
            df.rename(columns={'date': 'Ano'}, inplace=True)
            df['Ano'] = pd.to_numeric(df['Ano'], errors='coerce')
        
        return df
    
    def _generate_quality_report(self, df: pd.DataFrame, stage: str):
        """Gera relat√≥rio de qualidade dos dados"""
        numeric_cols = [col for col in df.columns if col not in ['Pa√≠s', 'Ano']]
        
        total_points = len(df) * len(numeric_cols)
        missing_points = df[numeric_cols].isnull().sum().sum()
        missing_percentage = (missing_points / total_points) * 100 if total_points > 0 else 0
        
        self.quality_report[stage] = {
            'total_countries': df['Pa√≠s'].nunique(),
            'total_observations': len(df),
            'missing_points': missing_points,
            'missing_percentage': missing_percentage,
            'period': f"{df['Ano'].min():.0f}-{df['Ano'].max():.0f}" if 'Ano' in df.columns else "N/A"
        }
    
    def _apply_multilevel_imputation(self, df: pd.DataFrame) -> pd.DataFrame:
        """Aplica estrat√©gia multin√≠vel de imputa√ß√£o para maximizar reten√ß√£o de pa√≠ses"""
        
        indicadores = [col for col in df.columns if col not in ['Pa√≠s', 'Ano']]
        
        def process_country_group(group):
            """Processa um pa√≠s espec√≠fico com m√∫ltiplas estrat√©gias"""
            group = group.copy()  # Evitar SettingWithCopyWarning
            country_data = group.set_index('Ano')[indicadores]
            
            # 1. Interpola√ß√£o linear (melhor para s√©ries temporais)
            country_data = country_data.interpolate(method='linear', limit_direction='both')
            
            # 2. Forward fill para dados iniciais
            country_data = country_data.ffill()
            
            # 3. Backward fill para dados finais
            country_data = country_data.bfill()
            
            # 4. Para gaps muito grandes, usar interpola√ß√£o polinomial suave
            for col in country_data.columns:
                if country_data[col].isnull().sum() > 0:
                    try:
                        country_data[col] = country_data[col].interpolate(method='polynomial', order=2)
                    except:
                        pass
            
            result = country_data.reset_index()
            result['Pa√≠s'] = group['Pa√≠s'].iloc[0]  # Adicionar pa√≠s de volta
            return result
        
        # Aplicar processamento por pa√≠s
        df_processed_list = []
        for pais, group in df.groupby('Pa√≠s'):
            processed_group = process_country_group(group)
            df_processed_list.append(processed_group)
        
        df_processed = pd.concat(df_processed_list, ignore_index=True)
        
        # Como √∫ltimo recurso, preenchimento com mediana regional
        df_processed = self._fill_with_regional_median(df_processed)
        
        # Remover outliers extremos
        df_processed = self._remove_extreme_outliers(df_processed)
        
        return df_processed
    
    def _fill_with_regional_median(self, df: pd.DataFrame) -> pd.DataFrame:
        """Preenche dados faltantes com mediana regional - VERS√ÉO CORRIGIDA"""
        df = df.copy()
        
        # Mapeamento de pa√≠ses para regi√µes
        region_mapping = {}
        for country in ZONA_DO_EURO:
            region_mapping[country] = 'Europa'
        for country in BRICS:
            region_mapping[country] = 'BRICS'
        for country in PAISES_SUL_AMERICA:
            region_mapping[country] = 'Am√©rica do Sul'
        for country in PAISES_SUDESTE_ASIATICO:
            region_mapping[country] = 'Sudeste Asi√°tico'
        
        df['Regi√£o'] = df['Pa√≠s'].map(region_mapping).fillna('Outros')
        
        numeric_cols = [col for col in df.columns if col not in ['Pa√≠s', 'Ano', 'Regi√£o']]
        
        for col in numeric_cols:
            # Verificar se h√° valores faltantes nesta coluna
            if df[col].isnull().sum() == 0:
                continue
                
            # Calcular mediana por regi√£o e ano - CORRIGIDO
            try:
                # Agrupar e calcular mediana de forma mais robusta
                regional_medians = df.groupby(['Regi√£o', 'Ano'])[col].median()
                
                # Preencher valores faltantes
                mask = df[col].isnull()
                
                for idx in df[mask].index:
                    region = df.loc[idx, 'Regi√£o']
                    year = df.loc[idx, 'Ano']
                    
                    # Tentar usar mediana regional por ano
                    try:
                        if pd.notna(regional_medians.loc[(region, year)]):
                            df.loc[idx, col] = regional_medians.loc[(region, year)]
                            continue
                    except (KeyError, TypeError):
                        pass
                    
                    # Fallback: mediana regional geral
                    try:
                        regional_median = df[df['Regi√£o'] == region][col].median()
                        if pd.notna(regional_median):
                            df.loc[idx, col] = regional_median
                            continue
                    except:
                        pass
                    
                    # √öltimo recurso: mediana global
                    try:
                        global_median = df[col].median()
                        if pd.notna(global_median):
                            df.loc[idx, col] = global_median
                        else:
                            df.loc[idx, col] = 0
                    except:
                        df.loc[idx, col] = 0
                        
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro ao processar coluna {col}: {e}")
                # Como fallback final, preencher com mediana global ou zero
                df[col].fillna(df[col].median() if pd.notna(df[col].median()) else 0, inplace=True)
        
        df.drop(columns=['Regi√£o'], inplace=True)
        
        # Preencher zeros finais se ainda houver NaNs
        df.fillna(0, inplace=True)
        
        return df
    
    def _remove_extreme_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """Remove outliers extremos usando m√©todo IQR por indicador"""
        df = df.copy()
        
        numeric_cols = [col for col in df.columns if col not in ['Pa√≠s', 'Ano']]
        
        for col in numeric_cols:
            Q1 = df[col].quantile(0.01)
            Q3 = df[col].quantile(0.99)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - 3 * IQR
            upper_bound = Q3 + 3 * IQR
            
            # Winsoriza√ß√£o ao inv√©s de remo√ß√£o
            df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)
        
        return df
    
    def _prepare_for_modeling(self, df: pd.DataFrame) -> pd.DataFrame:
        """Prepara dados para modelagem com engenharia de features"""
        try:
            df_model = df.copy().set_index(['Pa√≠s', 'Ano'])
            
            # Remover PIB per capita dos preditores
            if 'PIB_per_capita' in df_model.columns:
                target = df_model['PIB_per_capita']
                predictors_df = df_model.drop(columns=['PIB_per_capita'])
            else:
                st.error("‚ùå PIB_per_capita n√£o encontrado!")
                return None
            
            # Criar vari√°veis lag
            for var in predictors_df.columns:
                df_model[f'{var}_lag1'] = predictors_df.groupby('Pa√≠s')[var].shift(1)
                # Lag de 2 anos para algumas vari√°veis importantes
                if var in ['Formacao_Bruta_Capital', 'Alfabetizacao_Jovens', 'Cobertura_Internet']:
                    df_model[f'{var}_lag2'] = predictors_df.groupby('Pa√≠s')[var].shift(2)
            
            # Criar vari√°veis de crescimento
            for var in ['Formacao_Bruta_Capital', 'Valor_Exportacoes', 'Consumo_Familias']:
                if var in predictors_df.columns:
                    growth_var = f'{var}_growth'
                    df_model[growth_var] = predictors_df.groupby('Pa√≠s')[var].pct_change()
                    df_model[f'{growth_var}_lag1'] = df_model.groupby('Pa√≠s')[growth_var].shift(1)
            
            # Remover linhas com NaN ap√≥s criar lags
            df_model_clean = df_model.dropna()
            
            return df_model_clean
            
        except Exception as e:
            st.error(f"‚ùå Erro na prepara√ß√£o dos dados para modelagem: {e}")
            return None
    
    def get_quality_report(self) -> Dict:
        """Retorna relat√≥rio de qualidade dos dados"""
        return self.quality_report

class ModelTrainer:
    """Classe para treinar e avaliar m√∫ltiplos modelos de machine learning"""
    
    def __init__(self):
        self.models_config = {
            "Regress√£o Linear": LinearRegression(),
            "Ridge Regression": Ridge(alpha=1.0, random_state=42),
            "Lasso Regression": Lasso(alpha=0.1, random_state=42),
            "√Årvore de Decis√£o": DecisionTreeRegressor(max_depth=8, min_samples_split=10, random_state=42),
            "Random Forest": RandomForestRegressor(
                n_estimators=200, max_depth=8, min_samples_split=10, 
                random_state=42, n_jobs=-1
            ),
            "XGBoost": XGBRegressor(
                n_estimators=300, learning_rate=0.05, max_depth=6, 
                subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1
            )
        }
    
    def train_and_evaluate(self, df_model: pd.DataFrame) -> Dict:
        """Treina todos os modelos e retorna resultados comparativos"""
        global _cached_models
        
        if _cached_models is not None:
            return _cached_models
        
        TARGET = 'PIB_per_capita'
        PREDICTORS = [col for col in df_model.columns if col != TARGET and 
                     ('_lag1' in col or '_lag2' in col or '_growth_lag1' in col)]
        
        X = df_model[PREDICTORS]
        y = df_model[TARGET]
        
        # Normalizar features para alguns modelos
        X_normalized = (X - X.mean()) / X.std()
        
        results = []
        trained_models = {}
        
        progress_bar = st.progress(0)
        
        for i, (name, model) in enumerate(self.models_config.items()):
            st.info(f"ü§ñ Treinando modelo: {name}")
            
            try:
                # Usar dados normalizados para modelos lineares
                if name in ["Regress√£o Linear", "Ridge Regression", "Lasso Regression"]:
                    model.fit(X_normalized, y)
                    y_pred = model.predict(X_normalized)
                else:
                    model.fit(X, y)
                    y_pred = model.predict(X)
                
                # Calcular m√©tricas
                r2 = r2_score(y, y_pred)
                rmse = np.sqrt(mean_squared_error(y, y_pred))
                mae = mean_absolute_error(y, y_pred)
                
                # MAPE (Mean Absolute Percentage Error)
                mape = np.mean(np.abs((y - y_pred) / y)) * 100
                
                results.append({
                    'Modelo': name,
                    'R¬≤': round(r2, 4),
                    'RMSE': round(rmse, 2),
                    'MAE': round(mae, 2),
                    'MAPE': round(mape, 2)
                })
                
                trained_models[name] = model
                
                # Salvar import√¢ncia das features
                if hasattr(model, 'feature_importances_'):
                    importance = pd.Series(model.feature_importances_, index=PREDICTORS)
                    trained_models[f"{name}_importance"] = importance.sort_values(ascending=False)
                elif hasattr(model, 'coef_'):
                    # Para modelos lineares, usar valor absoluto dos coeficientes
                    importance = pd.Series(np.abs(model.coef_), index=PREDICTORS)
                    trained_models[f"{name}_importance"] = importance.sort_values(ascending=False)
                
            except Exception as e:
                st.error(f"‚ùå Erro ao treinar {name}: {e}")
                continue
            
            progress_bar.progress((i + 1) / len(self.models_config))
        
        progress_bar.empty()
        
        results_df = pd.DataFrame(results).sort_values('R¬≤', ascending=False)
        
        _cached_models = {
            'resultados': results_df,
            'modelos': trained_models,
            'X': X,
            'y': y,
            'predictors': PREDICTORS,
            'X_normalized': X_normalized
        }
        
        return _cached_models

# --- APLICA√á√ÉO STREAMLIT PRINCIPAL ---



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class EconomicProjectionSystem:
    """Sistema avan√ßado de proje√ß√µes econ√¥micas com m√∫ltiplos cen√°rios"""
    
    def __init__(self, df_model: pd.DataFrame, trained_models: Dict, models_results: pd.DataFrame):
        self.df_model = df_model
        self.trained_models = trained_models
        self.models_results = models_results
        self.base_indicators = self._get_base_indicators()
        
    def _get_base_indicators(self) -> List[str]:
        """Identifica indicadores base (sem lag/growth)"""
        all_cols = [col for col in self.df_model.columns if col != 'PIB_per_capita']
        base_indicators = []
        
        for col in all_cols:
            # Remove sufixos _lag1, _lag2, _growth, etc.
            base_name = col.replace('_lag1', '').replace('_lag2', '').replace('_growth_lag1', '').replace('_growth', '')
            if base_name not in base_indicators and base_name in self.df_model.columns:
                base_indicators.append(base_name)
                
        return base_indicators

    def create_projection_interface():
    """Cria interface Streamlit para proje√ß√µes econ√¥micas"""
    
    st.header("üîÆ Proje√ß√µes Econ√¥micas Avan√ßadas")
    
    # Verificar se os dados necess√°rios est√£o dispon√≠veis
    required_session_vars = ['df_model', 'models_data']
    missing_vars = [var for var in required_session_vars if var not in st.session_state]
    
    if missing_vars:
        st.error(f"‚ùå Dados necess√°rios n√£o encontrados: {missing_vars}")
        st.info("Por favor, execute primeiro a se√ß√£o de treinamento de modelos.")
        return
    
    df_model = st.session_state.df_model
    models_data = st.session_state.models_data
    
    # Inicializar sistema de proje√ß√µes
    projection_system = EconomicProjectionSystem(
        df_model=df_model,
        trained_models=models_data['modelos'],
        models_results=models_data['resultados']
    )
    
    # Configura√ß√µes da proje√ß√£o
    st.subheader("‚öôÔ∏è Configura√ß√µes da Proje√ß√£o")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        available_countries = sorted(df_model.reset_index()['Pa√≠s'].unique())
        selected_country = st.selectbox(
            "Pa√≠s para proje√ß√£o:",
            available_countries,
            help="Escolha o pa√≠s para an√°lise prospectiva"
        )
    
    with col2:
        years_ahead = st.slider(
            "Horizonte (anos):",
            min_value=1,
            max_value=10,
            value=5,
            help="N√∫mero de anos para projetar no futuro"
        )
    
    with col3:
        available_models = models_data['resultados']['Modelo'].tolist()
        selected_model = st.selectbox(
            "Modelo de proje√ß√£o:",
            available_models,
            index=0,
            help="Modelo de ML para fazer as proje√ß√µes"
        )
    
    st.subheader("üìä Cen√°rios Econ√¥micos")
    scenarios = projection_system.create_projection_scenarios()
    scenario_tabs = st.tabs(list(scenarios.keys()) + ["Personalizado"])
    projections_results = {}
    
    for i, (scenario_name, scenario_data) in enumerate(scenarios.items()):
        with scenario_tabs[i]:
            st.write(f"**{scenario_data['description']}**")
            st.write("**Principais ajustes anuais:**")
            adjustments_df = pd.DataFrame([
                {"Indicador": k.replace('_', ' ').title(), "Crescimento Anual": f"{v:+.1%}"}
                for k, v in scenario_data['adjustments'].items()
            ])
            st.dataframe(adjustments_df, use_container_width=True, hide_index=True)
            
            if st.button(f"üöÄ Calcular Proje√ß√£o - {scenario_name}", key=f"calc_{scenario_name}"):
                with st.spinner(f"Calculando proje√ß√£o {scenario_name}..."):
                    try:
                        future_data = projection_system.generate_future_data(
                            country=selected_country,
                            years_ahead=years_ahead,
                            scenario=scenario_name
                        )
                        results = projection_system.make_projections(future_data, selected_model)
                        projections_results[scenario_name] = results
                        
                        st.success(f"‚úÖ Proje√ß√£o {scenario_name} calculada com sucesso!")
                        initial_gdp = results['predicoes'][0]
                        final_gdp = results['predicoes'][-1]
                        cagr = ((final_gdp / initial_gdp) ** (1/years_ahead) - 1) * 100
                        
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("PIB per capita inicial", f"${initial_gdp:,.0f}")
                        with col_b:
                            st.metric("PIB per capita final", f"${final_gdp:,.0f}")
                        with col_c:
                            st.metric("Crescimento anual m√©dio", f"{cagr:+.1f}%")
                    except Exception as e:
                        st.error(f"‚ùå Erro ao calcular proje√ß√£o: {str(e)}")
    
    with scenario_tabs[-1]:
        st.write("**Crie seu pr√≥prio cen√°rio econ√¥mico**")
        custom_adjustments = {}
        col1, col2 = st.columns(2)
        key_indicators = [
            "Formacao_Bruta_Capital", "Valor_Exportacoes", "Consumo_Familias",
            "Investimento_Estrangeiro_Direto", "Cobertura_Internet", 
            "Alfabetizacao_Jovens", "Desemprego", "Inflacao_Anual_Consumidor"
        ]
        
        for i, indicator in enumerate(key_indicators):
            col = col1 if i % 2 == 0 else col2
            with col:
                display_name = indicator.replace('_', ' ').title()
                adjustment = st.slider(
                    f"{display_name}:",
                    min_value=-0.10,
                    max_value=0.15,
                    value=0.02,
                    step=0.005,
                    format="%.1%%",
                    key=f"custom_{indicator}",
                    help=f"Crescimento anual para {display_name}"
                )
                custom_adjustments[indicator] = adjustment
        
        if st.button("üéØ Calcular Cen√°rio Personalizado", key="calc_custom"):
            with st.spinner("Calculando cen√°rio personalizado..."):
                try:
                    future_data = projection_system.generate_future_data(
                        country=selected_country,
                        years_ahead=years_ahead,
                        scenario="custom",
                        custom_adjustments=custom_adjustments
                    )
                    results = projection_system.make_projections(future_data, selected_model)
                    projections_results["Personalizado"] = results
                    
                    st.success("‚úÖ Cen√°rio personalizado calculado com sucesso!")
                    initial_gdp = results['predicoes'][0]
                    final_gdp = results['predicoes'][-1]
                    cagr = ((final_gdp / initial_gdp) ** (1/years_ahead) - 1) * 100
                    
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("PIB per capita inicial", f"${initial_gdp:,.0f}")
                    with col_b:
                        st.metric("PIB per capita final", f"${final_gdp:,.0f}")
                    with col_c:
                        st.metric("Crescimento anual m√©dio", f"{cagr:+.1f}%")
                except Exception as e:
                    st.error(f"‚ùå Erro ao calcular cen√°rio personalizado: {str(e)}")
    
    if projections_results:
        st.subheader("üìà Compara√ß√£o de Cen√°rios")
        fig, ax = plt.subplots(figsize=(12, 8))
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
        
        for i, (scenario, results) in enumerate(projections_results.items()):
            color = colors[i % len(colors)]
            ax.plot(results['anos'], results['predicoes'], 
                    marker='o', linewidth=3, markersize=6, 
                    label=scenario, color=color, alpha=0.9)
            ax.fill_between(results['anos'], 
                            results['intervalo_inferior'], 
                            results['intervalo_superior'],
                            alpha=0.2, color=color)
        
        ax.set_title(f'Proje√ß√µes do PIB per capita - {selected_country}', 
                     fontsize=16, fontweight='bold')
        ax.set_xlabel('Ano', fontsize=12)
        ax.set_ylabel('PIB per capita (US$)', fontsize=12)
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        ax.grid(True, alpha=0.3)
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()
        
        st.subheader("üìä Resumo Comparativo dos Cen√°rios")
        comparison_data = []
        for scenario, results in projections_results.items():
            initial_gdp = results['predicoes'][0]
            final_gdp = results['predicoes'][-1]
            cagr = ((final_gdp / initial_gdp) ** (1/years_ahead) - 1) * 100
            total_growth = ((final_gdp / initial_gdp) - 1) * 100
            
            comparison_data.append({
                'Cen√°rio': scenario,
                'PIB Inicial (US$)': f"${initial_gdp:,.0f}",
                'PIB Final (US$)': f"${final_gdp:,.0f}",
                'Crescimento Total': f"{total_growth:+.1f}%",
                'Crescimento Anual': f"{cagr:+.1f}%",
                'Modelo R¬≤': f"{results['r2']:.3f}"
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)
        
        st.subheader("üíæ Exportar Resultados")
        col1, col2 = st.columns(2)
        
        with col1:
            all_projections = []
            for scenario, results in projections_results.items():
                for i, year in enumerate(results['anos']):
                    all_projections.append({
                        'Pa√≠s': selected_country,
                        'Cen√°rio': scenario,
                        'Ano': year,
                        'PIB_per_capita_projetado': results['predicoes'][i],
                        'Intervalo_Inferior': results['intervalo_inferior'][i],
                        'Intervalo_Superior': results['intervalo_superior'][i],
                        'Modelo': results['modelo_usado']
                    })
            projections_df = pd.DataFrame(all_projections)
            csv_data = projections_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Baixar Proje√ß√µes (CSV)",
                data=csv_data,
                file_name=f"projecoes_{selected_country}_{years_ahead}anos.csv",
                mime='text/csv'
            )
        
        with col2:
            report = f\"""RELAT√ìRIO DE PROJE√á√ïES ECON√îMICAS
{selected_country} - Horizonte: {years_ahead} anos
Modelo utilizado: {selected_model}
Gerado em: {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M')}

RESUMO EXECUTIVO:
\"""
            for scenario, results in projections_results.items():
                initial_gdp = results['predicoes'][0]
                final_gdp = results['predicoes'][-1]
                cagr = ((final_gdp / initial_gdp) ** (1/years_ahead) - 1) * 100
                report += f\"""\n{scenario.upper()}:
‚Ä¢ PIB per capita inicial: ${initial_gdp:,.0f}
‚Ä¢ PIB per capita final: ${final_gdp:,.0f}
‚Ä¢ Crescimento anual m√©dio: {cagr:+.2f}%
‚Ä¢ R¬≤ do modelo: {results['r2']:.3f}
\"""
            report += f\""""

METODOLOGIA:
‚Ä¢ Modelo de proje√ß√£o: {selected_model}
‚Ä¢ Precis√£o do modelo (RMSE): ${models_data['resultados'].iloc[0]['RMSE']:,.0f}
‚Ä¢ Intervalo de confian√ßa: ¬±95%
‚Ä¢ Features utilizadas: {len(models_data['predictors'])} vari√°veis

DISCLAIMER:
As proje√ß√µes s√£o baseadas em modelos econom√©tricos e cen√°rios 
hipot√©ticos. Resultados reais podem variar significativamente 
devido a choques externos, mudan√ßas pol√≠ticas e outros fatores 
n√£o previstos nos modelos.

Sistema "C√≥digo da Riqueza" - Vers√£o Proje√ß√µes
\"""
            st.download_button(
                label="üìÑ Baixar Relat√≥rio",
                data=report.encode('utf-8'),
                file_name=f"relatorio_projecoes_{selected_country}.txt",
                mime='text/plain'
            )


def add_projections_to_main():
    """Adiciona funcionalidade de proje√ß√µes ao sistema principal"""
    
    # Adicionar na navega√ß√£o principal (ap√≥s a se√ß√£o de modelos)
    st.markdown("---")
    
    # Verificar se os modelos foram treinados
    if 'models_data' in st.session_state and 'df_model' in st.session_state:
        create_projection_interface()
    else:
        st.info("üîÑ Execute primeiro a se√ß√£o de treinamento de modelos para habilitar as proje√ß√µes.")


def main():
    st.set_page_config(
        page_title="C√≥digo da Riqueza - An√°lise Econom√©trica Avan√ßada", 
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("üèõÔ∏è O C√≥digo da Riqueza ‚Äî An√°lise Econom√©trica Avan√ßada")
    st.markdown("""
    ### üìà Sistema Avan√ßado de An√°lise e Proje√ß√£o Econ√¥mica
    
    Utilizando dados do Banco Mundial e t√©cnicas avan√ßadas de machine learning para 
    an√°lise preditiva do PIB per capita com base em 21 indicadores econ√¥micos fundamentais.
    
    **üîß Recursos desta vers√£o:**
    - ‚úÖ Sistema robusto de cache e retry para API do Banco Mundial
    - ‚úÖ Estrat√©gia multin√≠vel de imputa√ß√£o de dados
    - ‚úÖ 6 modelos de ML com avalia√ß√£o comparativa
    - ‚úÖ An√°lise de import√¢ncia das vari√°veis
    - ‚úÖ Interface interativa completa
    """)
    
    # Inicializa√ß√£o dos dados
    if not all(key in st.session_state for key in ['df', 'df_model', 'quality_report']):
        with st.spinner("üîÑ Inicializando sistema e carregando dados..."):
            
            # Carregar dados
            loader = WorldBankDataLoader()
            df_raw = loader.load_with_cache_and_retry()
            
            if df_raw is None:
                st.error("‚ùå Falha cr√≠tica ao carregar dados do Banco Mundial")
                st.stop()
            
            # Processar dados
            processor = DataProcessor()
            df, df_model = processor.process_data(df_raw)
            
            if df is None or df_model is None:
                st.error("‚ùå Falha no processamento dos dados")
                st.stop()
            
            # Armazenar na sess√£o
            st.session_state.df = df
            st.session_state.df_model = df_model
            st.session_state.quality_report = processor.get_quality_report()
    
    df = st.session_state.df
    df_model = st.session_state.df_model
    quality_report = st.session_state.quality_report
    
    # --- SE√á√ÉO: RELAT√ìRIO DE QUALIDADE DOS DADOS ---
    st.header("üìä Relat√≥rio de Qualidade dos Dados")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Pa√≠ses Analisados", 
            quality_report['final']['total_countries'],
            delta=None
        )
    
    with col2:
        st.metric(
            "Total de Observa√ß√µes", 
            f"{quality_report['final']['total_observations']:,}",
            delta=None
        )
    
    with col3:
        st.metric(
            "Per√≠odo de An√°lise", 
            quality_report['final']['period'],
            delta=None
        )
    
    with col4:
        initial_missing = quality_report['inicial']['missing_percentage']
        final_missing = quality_report['final']['missing_percentage']
        st.metric(
            "Dados Imputados", 
            f"{final_missing:.1f}%",
            delta=f"{final_missing - initial_missing:.1f}%"
        )
    
    if final_missing > 0:
        st.info(f"""
        üìã **Relat√≥rio de Imputa√ß√£o**: {initial_missing:.1f}% dos dados originais estavam faltantes. 
        Ap√≥s aplicar estrat√©gias multin√≠vel de imputa√ß√£o (interpola√ß√£o, preenchimento regional, 
        e fallbacks), conseguimos reduzir para {final_missing:.1f}% e manter 
        {quality_report['final']['total_countries']} pa√≠ses na an√°lise.
        """)
    else:
        st.success("‚úÖ Todos os dados foram processados com sucesso, sem necessidade de imputa√ß√£o significativa!")
    
    # Treinar modelos
    if 'models_data' not in st.session_state:
        with st.spinner("ü§ñ Treinando e avaliando modelos de machine learning..."):
            trainer = ModelTrainer()
            models_data = trainer.train_and_evaluate(df_model)
            st.session_state.models_data = models_data
    
    models_data = st.session_state.models_data
    
    # --- SE√á√ÉO: COMPARA√á√ÉO DE MODELOS ---
    st.header("üéØ Compara√ß√£o de Modelos de Machine Learning")
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.subheader("üìà Performance Comparativa")
        
        results_df = models_data['resultados']
        
        # Gr√°fico de barras comparativo
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # R¬≤
        axes[0,0].bar(results_df['Modelo'], results_df['R¬≤'], color='skyblue', alpha=0.8)
        axes[0,0].set_title('R¬≤ Score (maior √© melhor)', fontweight='bold')
        axes[0,0].set_ylabel('R¬≤')
        axes[0,0].tick_params(axis='x', rotation=45)
        axes[0,0].grid(True, alpha=0.3)
        
        # RMSE
        axes[0,1].bar(results_df['Modelo'], results_df['RMSE'], color='lightcoral', alpha=0.8)
        axes[0,1].set_title('RMSE (menor √© melhor)', fontweight='bold')
        axes[0,1].set_ylabel('RMSE (US$)')
        axes[0,1].tick_params(axis='x', rotation=45)
        axes[0,1].grid(True, alpha=0.3)
        
        # MAE
        axes[1,0].bar(results_df['Modelo'], results_df['MAE'], color='lightgreen', alpha=0.8)
        axes[1,0].set_title('MAE (menor √© melhor)', fontweight='bold')
        axes[1,0].set_ylabel('MAE (US$)')
        axes[1,0].tick_params(axis='x', rotation=45)
        axes[1,0].grid(True, alpha=0.3)
        
        # MAPE
        axes[1,1].bar(results_df['Modelo'], results_df['MAPE'], color='gold', alpha=0.8)
        axes[1,1].set_title('MAPE % (menor √© melhor)', fontweight='bold')
        axes[1,1].set_ylabel('MAPE (%)')
        axes[1,1].tick_params(axis='x', rotation=45)
        axes[1,1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()
    
    with col2:
        st.subheader("üèÜ Ranking dos Modelos")
        
        # Adicionar interpreta√ß√£o das m√©tricas
        for i, row in results_df.iterrows():
            if i == 0:  # Melhor modelo
                st.success(f"""
                **ü•á {row['Modelo']}**  
                R¬≤: {row['R¬≤']:.4f} | RMSE: ${row['RMSE']:,.0f} | MAE: ${row['MAE']:,.0f} | MAPE: {row['MAPE']:.1f}%
                """)
            elif i == 1:  # Segundo melhor
                st.info(f"""
                **ü•à {row['Modelo']}**  
                R¬≤: {row['R¬≤']:.4f} | RMSE: ${row['RMSE']:,.0f} | MAE: ${row['MAE']:,.0f} | MAPE: {row['MAPE']:.1f}%
                """)
            elif i == 2:  # Terceiro melhor
                st.warning(f"""
                **ü•â {row['Modelo']}**  
                R¬≤: {row['R¬≤']:.4f} | RMSE: ${row['RMSE']:,.0f} | MAE: ${row['MAE']:,.0f} | MAPE: {row['MAPE']:.1f}%
                """)
            else:
                st.text(f"""
                {row['Modelo']}  
                R¬≤: {row['R¬≤']:.4f} | RMSE: ${row['RMSE']:,.0f} | MAE: ${row['MAE']:,.0f} | MAPE: {row['MAPE']:.1f}%
                """)
        
        best_model = results_df.iloc[0]
        st.markdown(f"""
        ---
        ### üéØ Interpreta√ß√£o do Melhor Modelo
        
        **{best_model['Modelo']}** explica **{best_model['R¬≤']:.1%}** da varia√ß√£o do PIB per capita.
        
        - **Erro m√©dio**: ¬±${best_model['RMSE']:,.0f}
        - **Erro absoluto**: ${best_model['MAE']:,.0f}  
        - **Erro percentual**: {best_model['MAPE']:.1f}%
        """)
    
    # --- SELE√á√ÉO DO MODELO ---
    st.subheader("‚öôÔ∏è Configura√ß√£o do Modelo para An√°lises")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        selected_model_name = st.selectbox(
            "Selecione o modelo para an√°lises:",
            options=results_df['Modelo'].tolist(),
            index=0,
            help="O melhor modelo √© selecionado por padr√£o"
        )
        
        selected_model = models_data['modelos'][selected_model_name]
        
        # Mostrar import√¢ncia das vari√°veis
        importance_key = f"{selected_model_name}_importance"
        if importance_key in models_data['modelos']:
            st.subheader("üìä Top 10 Vari√°veis Mais Importantes")
            
            importance = models_data['modelos'][importance_key]
            top_10 = importance.head(10)
            
            # Gr√°fico de import√¢ncia
            fig, ax = plt.subplots(figsize=(10, 6))
            bars = ax.barh(range(len(top_10)), top_10.values, color='steelblue', alpha=0.8)
            ax.set_yticks(range(len(top_10)))
            ax.set_yticklabels([var.replace('_lag1', '').replace('_lag2', '').replace('_growth_lag1', ' (crescimento)').replace('_', ' ').title() 
                               for var in top_10.index])
            ax.set_xlabel('Import√¢ncia Relativa')
            ax.set_title(f'Import√¢ncia das Vari√°veis - {selected_model_name}', fontweight='bold')
            ax.grid(True, alpha=0.3, axis='x')
            
            # Adicionar valores nas barras
            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax.text(width, bar.get_y() + bar.get_height()/2, 
                       f'{width:.3f}', ha='left', va='center', fontweight='bold')
            
            plt.tight_layout()
            st.pyplot(fig)
            plt.close()
    
    with col2:
        # M√©tricas detalhadas do modelo selecionado
        model_info = results_df[results_df['Modelo'] == selected_model_name].iloc[0]
        
        st.subheader(f"üìã Detalhes do Modelo: {selected_model_name}")
        
        col_a, col_b, col_c, col_d = st.columns(4)
        with col_a:
            st.metric("R¬≤ Score", f"{model_info['R¬≤']:.4f}")
        with col_b:
            st.metric("RMSE", f"${model_info['RMSE']:,.0f}")
        with col_c:
            st.metric("MAE", f"${model_info['MAE']:,.0f}")
        with col_d:
            st.metric("MAPE", f"{model_info['MAPE']:.1f}%")
        
        # Interpreta√ß√£o contextualizada
        if model_info['R¬≤'] >= 0.8:
            performance_level = "Excelente"
        elif model_info['R¬≤'] >= 0.6:
            performance_level = "Bom"
        else:
            performance_level = "Limitado"
        
        if performance_level == "Excelente":
            st.success(f"""
            **Performance: {performance_level}**
            
            Este modelo tem poder explicativo **{performance_level.lower()}** para prever o PIB per capita.
            Com erro m√©dio de ${model_info['MAE']:,.0f}, as proje√ß√µes t√™m precis√£o de 
            ¬±{model_info['MAPE']:.1f}% em m√©dia.
            """)
        elif performance_level == "Bom":
            st.info(f"""
            **Performance: {performance_level}**
            
            Este modelo tem poder explicativo **{performance_level.lower()}** para prever o PIB per capita.
            Com erro m√©dio de ${model_info['MAE']:,.0f}, as proje√ß√µes t√™m precis√£o de 
            ¬±{model_info['MAPE']:.1f}% em m√©dia.
            """)
        else:
            st.warning(f"""
            **Performance: {performance_level}**
            
            Este modelo tem poder explicativo **{performance_level.lower()}** para prever o PIB per capita.
            Com erro m√©dio de ${model_info['MAE']:,.0f}, as proje√ß√µes t√™m precis√£o de 
            ¬±{model_info['MAPE']:.1f}% em m√©dia.
            """)
        
        # Informa√ß√µes do dataset
        st.info(f"""
        **üìà Dataset utilizado:**
        - **Observa√ß√µes**: {len(models_data['y']):,}
        - **Vari√°veis preditoras**: {len(models_data['predictors'])}
        - **Pa√≠ses**: {df['Pa√≠s'].nunique()}
        - **Per√≠odo**: {df['Ano'].min():.0f}-{df['Ano'].max():.0f}
        """)
    
    # --- AN√ÅLISE POR PA√çS ---
    st.header("üåç An√°lise Econ√¥mica por Pa√≠s")
    
    # Sidebar com filtros
    st.sidebar.header("üîç Configura√ß√µes de An√°lise")
    
    available_countries = sorted(df['Pa√≠s'].unique())
    selected_country = st.sidebar.selectbox(
        "Selecionar pa√≠s para an√°lise:",
        available_countries,
        help="Escolha o pa√≠s para an√°lise detalhada"
    )
    
    # Filtros de ano
    available_years = sorted(df[df['Pa√≠s'] == selected_country]['Ano'].unique())
    if len(available_years) > 1:
        year_start, year_end = st.sidebar.select_slider(
            "Per√≠odo hist√≥rico:",
            options=available_years,
            value=(available_years[0], available_years[-1]),
            help="Define o intervalo de anos para an√°lise hist√≥rica"
        )
    else:
        year_start = year_end = available_years[0]
    
    # Dados filtrados
    df_filtered = df[
        (df['Pa√≠s'] == selected_country) & 
        (df['Ano'].between(year_start, year_end))
    ]
    
    # --- VISUALIZA√á√ÉO HIST√ìRICA ---
    st.subheader(f"üìà Evolu√ß√£o Hist√≥rica ‚Äî {selected_country} ({year_start:.0f}‚Äì{year_end:.0f})")
    
    # Seletor de indicador
    available_indicators = [col for col in df.columns if col not in ['Pa√≠s', 'Ano']]
    selected_indicator = st.selectbox(
        "Indicador para visualiza√ß√£o:",
        available_indicators,
        index=0 if 'PIB_per_capita' in available_indicators else 0,
        help="Escolha o indicador econ√¥mico para visualizar sua evolu√ß√£o"
    )
    
    if not df_filtered.empty:
        # Gr√°fico de linha com √°rea
        fig, ax = plt.subplots(figsize=(12, 6))
        
        x_data = df_filtered['Ano']
        y_data = df_filtered[selected_indicator]
        
        # Linha principal
        ax.plot(x_data, y_data, marker='o', linewidth=3, markersize=6, 
                color='steelblue', alpha=0.9, label=selected_indicator.replace('_', ' ').title())
        
        # √Årea sob a curva
        ax.fill_between(x_data, y_data, alpha=0.3, color='steelblue')
        
        # Linha de tend√™ncia
        if len(x_data) > 2:
            z = np.polyfit(x_data, y_data, 1)
            p = np.poly1d(z)
            ax.plot(x_data, p(x_data), "--", color='red', alpha=0.8, linewidth=2, label='Tend√™ncia')
        
        ax.set_title(f'{selected_indicator.replace("_", " ").title()} ‚Äî {selected_country}', 
                    fontsize=16, fontweight='bold')
        ax.set_xlabel('Ano', fontsize=12)
        ax.set_ylabel(selected_indicator.replace('_', ' ').title(), fontsize=12)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Adicionar anota√ß√µes para valores m√°ximo e m√≠nimo - VERS√ÉO CORRIGIDA
        try:
            if len(y_data) > 0 and not y_data.empty:
                # Encontrar √≠ndices v√°lidos
                max_idx = y_data.idxmax()
                min_idx = y_data.idxmin()
                
                # Verificar se os √≠ndices existem em ambas as s√©ries
                if max_idx in x_data.index and max_idx in y_data.index:
                    max_x = x_data.loc[max_idx]
                    max_y = y_data.loc[max_idx]
                    ax.annotate(f'M√°x: {max_y:,.0f}', 
                               xy=(max_x, max_y),
                               xytext=(10, 10), textcoords='offset points',
                               bbox=dict(boxstyle='round,pad=0.3', facecolor='green', alpha=0.7),
                               arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
                
                if min_idx in x_data.index and min_idx in y_data.index:
                    min_x = x_data.loc[min_idx]
                    min_y = y_data.loc[min_idx]
                    ax.annotate(f'M√≠n: {min_y:,.0f}', 
                               xy=(min_x, min_y),
                               xytext=(10, -20), textcoords='offset points',
                               bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.7),
                               arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
        except Exception as e:
            # Se houver erro nas anota√ß√µes, continua sem elas
            st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel adicionar anota√ß√µes de m√°x/m√≠n: {e}")
            pass
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close()
        
        # Estat√≠sticas resumidas - VERS√ÉO CORRIGIDA
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            try:
                current_value = y_data.iloc[-1] if len(y_data) > 0 else 0
                st.metric("Valor Atual", f"{current_value:,.0f}")
            except:
                st.metric("Valor Atual", "N/A")
                
        with col2:
            try:
                if len(y_data) > 1:
                    initial_value = y_data.iloc[0]
                    final_value = y_data.iloc[-1]
                    if initial_value > 0:
                        growth_rate = ((final_value / initial_value) ** (1/(len(y_data)-1)) - 1) * 100
                    else:
                        growth_rate = 0
                else:
                    growth_rate = 0
                st.metric("Crescimento Anual M√©dio", f"{growth_rate:+.1f}%")
            except:
                st.metric("Crescimento Anual M√©dio", "N/A")
                
        with col3:
            try:
                max_value = y_data.max() if len(y_data) > 0 else 0
                st.metric("M√°ximo Hist√≥rico", f"{max_value:,.0f}")
            except:
                st.metric("M√°ximo Hist√≥rico", "N/A")
                
        with col4:
            try:
                min_value = y_data.min() if len(y_data) > 0 else 0
                st.metric("M√≠nimo Hist√≥rico", f"{min_value:,.0f}")
            except:
                st.metric("M√≠nimo Hist√≥rico", "N/A")
    
    else:
        st.warning("‚ö†Ô∏è Nenhum dado dispon√≠vel para os filtros selecionados")
    
    # --- DADOS E DOWNLOADS ---
    st.header("üìã Dados e An√°lises Complementares")
    
    # Dados filtrados do pa√≠s selecionado
    st.subheader(f"üìä Dados Hist√≥ricos ‚Äî {selected_country}")
    
    if not df_filtered.empty:
        # Mostrar estat√≠sticas resumidas
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**üìà Estat√≠sticas Descritivas**")
            numeric_cols = [col for col in df_filtered.columns if col not in ['Pa√≠s', 'Ano']]
            stats_df = df_filtered[numeric_cols].describe().round(2)
            st.dataframe(stats_df)
        
        with col2:
            st.write("**üìä Correla√ß√µes com PIB per capita**")
            try:
                if 'PIB_per_capita' in df_filtered.columns and len(df_filtered) > 1:
                    # Verificar se h√° dados suficientes
                    pib_data = df_filtered['PIB_per_capita'].dropna()
                    if len(pib_data) > 1:
                        correlations = df_filtered[numeric_cols].corr()['PIB_per_capita'].sort_values(ascending=False)
                        correlations = correlations.drop('PIB_per_capita', errors='ignore').head(10)
                        
                        if len(correlations) > 0:
                            # Gr√°fico de correla√ß√µes
                            fig, ax = plt.subplots(figsize=(8, 6))
                            colors = ['green' if x > 0 else 'red' for x in correlations.values]
                            bars = ax.barh(range(len(correlations)), correlations.values, color=colors, alpha=0.7)
                            ax.set_yticks(range(len(correlations)))
                            ax.set_yticklabels([col.replace('_', ' ').title() for col in correlations.index])
                            ax.set_xlabel('Correla√ß√£o com PIB per capita')
                            ax.set_title('Top 10 Correla√ß√µes', fontweight='bold')
                            ax.grid(True, alpha=0.3, axis='x')
                            ax.axvline(x=0, color='black', linewidth=0.8)
                            
                            # Adicionar valores nas barras
                            for bar, value in zip(bars, correlations.values):
                                width = bar.get_width()
                                ax.text(width + (0.02 if width > 0 else -0.02), bar.get_y() + bar.get_height()/2, 
                                       f'{value:.2f}', ha='left' if width > 0 else 'right', va='center', fontweight='bold')
                            
                            plt.tight_layout()
                            st.pyplot(fig)
                            plt.close()
                        else:
                            st.info("üìä N√£o h√° correla√ß√µes significativas para exibir")
                    else:
                        st.info("üìä Dados insuficientes para an√°lise de correla√ß√£o")
                else:
                    st.info("üìä PIB per capita n√£o dispon√≠vel para an√°lise de correla√ß√£o")
                    
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro ao calcular correla√ß√µes: {e}")
                st.info("üìä An√°lise de correla√ß√£o n√£o dispon√≠vel para este pa√≠s/per√≠odo")
        
        # Tabela de dados completos
        st.write("**üìã Dados Completos do Per√≠odo Selecionado**")
        
        # Formatar dados para visualiza√ß√£o
        df_display = df_filtered.copy()
        
        # Formatar colunas monet√°rias
        money_cols = ['PIB_per_capita', 'Renda_Nacional_Bruta_per_Capita', 'Formacao_Bruta_Capital', 
                     'Valor_Exportacoes', 'Consumo_Familias', 'Investimento_Estrangeiro_Direto']
        
        for col in money_cols:
            if col in df_display.columns:
                df_display[col] = df_display[col].apply(lambda x: f"${x:,.0f}" if pd.notna(x) else "N/A")
        
        # Formatar colunas de percentual
        pct_cols = ['Alfabetizacao_Jovens', 'Participacao_Forca_Trabalho', 'Cobertura_Internet', 
                   'Acesso_Eletricidade', 'Desemprego', 'Conclusao_Ensino_Primario', 'Cobertura_Agua_Potavel',
                   'Gastos_Governamentais_Educacao', 'Gastos_Militares_perc_PIB', 'Exportacoes_Alta_Tecnologia_perc']
        
        for col in pct_cols:
            if col in df_display.columns:
                df_display[col] = df_display[col].apply(lambda x: f"{x:.1f}%" if pd.notna(x) else "N/A")
        
        st.dataframe(df_display, use_container_width=True)
        
        # Bot√µes de download
        col1, col2 = st.columns(2)
        
        with col1:
            csv_data = df_filtered.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Baixar Dados como CSV",
                data=csv_data,
                file_name=f"{selected_country}_dados_historicos.csv",
                mime='text/csv'
            )
        
        with col2:
            # Criar relat√≥rio resumido - VERS√ÉO CORRIGIDA
            report = f"""
RELAT√ìRIO ECON√îMICO - {selected_country}
Per√≠odo: {year_start:.0f} - {year_end:.0f}
Gerado em: {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M')}

INDICADORES PRINCIPAIS:
"""
            
            try:
                if 'PIB_per_capita' in df_filtered.columns and len(df_filtered) > 0:
                    pib_data = df_filtered['PIB_per_capita'].dropna()
                    if len(pib_data) > 1:
                        pib_inicial = pib_data.iloc[0]
                        pib_final = pib_data.iloc[-1]
                        if pib_inicial > 0:
                            crescimento_periodo = ((pib_final / pib_inicial) ** (1/(len(pib_data)-1)) - 1) * 100
                        else:
                            crescimento_periodo = 0
                        
                        report += f"""
‚Ä¢ PIB per capita inicial: ${pib_inicial:,.0f}
‚Ä¢ PIB per capita final: ${pib_final:,.0f}
‚Ä¢ Crescimento anual m√©dio: {crescimento_periodo:.2f}%

"""
                    elif len(pib_data) == 1:
                        report += f"""
‚Ä¢ PIB per capita: ${pib_data.iloc[0]:,.0f}
‚Ä¢ Dados dispon√≠veis apenas para um ano

"""
                
                # Adicionar outros indicadores importantes - COM VERIFICA√á√ÉO
                key_indicators = ['Alfabetizacao_Jovens', 'Desemprego', 'Cobertura_Internet', 'Gini']
                for indicator in key_indicators:
                    if indicator in df_filtered.columns:
                        indicator_data = df_filtered[indicator].dropna()
                        if len(indicator_data) >= 2:
                            initial_val = indicator_data.iloc[0]
                            final_val = indicator_data.iloc[-1]
                            change = final_val - initial_val
                            report += f"‚Ä¢ {indicator.replace('_', ' ')}: {initial_val:.1f} ‚Üí {final_val:.1f} ({change:+.1f})\n"
                        elif len(indicator_data) == 1:
                            report += f"‚Ä¢ {indicator.replace('_', ' ')}: {indicator_data.iloc[0]:.1f}\n"
                
            except Exception as e:
                report += f"\n‚ö†Ô∏è Erro ao processar alguns indicadores: {str(e)}\n"
            
            report += f"""

MODELO UTILIZADO: {selected_model_name}
R¬≤ Score: {models_data['resultados'].iloc[0]['R¬≤']:.4f}
RMSE: ${models_data['resultados'].iloc[0]['RMSE']:,.0f}

Relat√≥rio gerado pelo Sistema de An√°lise Econ√¥mica "C√≥digo da Riqueza"
"""
            
            st.download_button(
                label="üìÑ Baixar Relat√≥rio",
                data=report.encode('utf-8'),
                file_name=f"{selected_country}_relatorio_economico.txt",
                mime='text/plain'
            )
    
    else:
        st.warning("‚ö†Ô∏è Nenhum dado dispon√≠vel para o pa√≠s e per√≠odo selecionados")
    
    
    # --- PROJE√á√ïES ECON√îMICAS ---
    add_projections_to_main()

# --- INFORMA√á√ïES T√âCNICAS ---
    with st.expander("üîç Informa√ß√µes T√©cnicas e Metodologia"):
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä Especifica√ß√µes do Dataset")
            
            st.write(f"""
            **Fonte dos Dados**: Banco Mundial (World Bank Open Data)
            
            **Per√≠odo de An√°lise**: {df['Ano'].min():.0f} - {df['Ano'].max():.0f}
            
            **Pa√≠ses Inclu√≠dos**: {df['Pa√≠s'].nunique()} pa√≠ses
            
            **Total de Observa√ß√µes**: {len(df):,}
            
            **Indicadores Analisados**: {len([col for col in df.columns if col not in ['Pa√≠s', 'Ano']])}
            
            **Qualidade dos Dados**:
            - Dados originais faltantes: {quality_report['inicial']['missing_percentage']:.1f}%
            - Dados ap√≥s imputa√ß√£o: {quality_report['final']['missing_percentage']:.1f}%
            """)
            
            st.subheader("üéØ Indicadores Inclu√≠dos")
            
            indicators_by_category = {
                "üí∞ Econ√¥micos": [
                    "PIB_per_capita", "Formacao_Bruta_Capital", "Renda_Nacional_Bruta_per_Capita",
                    "Valor_Exportacoes", "Consumo_Familias", "Investimento_Estrangeiro_Direto",
                    "Inflacao_Anual_Consumidor", "Divida_Governo_Central_perc_PIB"
                ],
                "üéì Capital Humano": [
                    "Alfabetizacao_Jovens", "Conclusao_Ensino_Primario", 
                    "Gastos_Governamentais_Educacao", "Expectativa_de_Vida"
                ],
                "üíº Trabalho": [
                    "Participacao_Forca_Trabalho", "Desemprego"
                ],
                "üèóÔ∏è Infraestrutura": [
                    "Cobertura_Internet", "Acesso_Eletricidade", "Cobertura_Agua_Potavel",
                    "Exportacoes_Alta_Tecnologia_perc"
                ],
                "‚öñÔ∏è Governan√ßa": [
                    "Gini", "Qualidade_Regulatoria", "Gastos_Militares_perc_PIB"
                ]
            }
            
            for category, indicators in indicators_by_category.items():
                st.write(f"**{category}**")
                for indicator in indicators:
                    if indicator in df.columns:
                        # Calcular c√≥digo do World Bank
                        wb_code = [k for k, v in INDICADORES.items() if v == indicator]
                        wb_code = wb_code[0] if wb_code else "N/A"
                        st.write(f"  ‚Ä¢ {indicator.replace('_', ' ')}")
        
        with col2:
            st.subheader("ü§ñ Metodologia de Machine Learning")
            
            st.write("""
            **Abordagem de Modelagem**:
            
            1. **Engenharia de Features**:
               - Vari√°veis lag (t-1 e t-2)
               - Taxas de crescimento
               - Normaliza√ß√£o para modelos lineares
            
            2. **Modelos Testados**:
               - Regress√£o Linear
               - Ridge Regression (regulariza√ß√£o L2)
               - Lasso Regression (regulariza√ß√£o L1)
               - √Årvore de Decis√£o
               - Random Forest
               - XGBoost
            
            3. **M√©tricas de Avalia√ß√£o**:
               - R¬≤ Score (coeficiente de determina√ß√£o)
               - RMSE (erro quadr√°tico m√©dio)
               - MAE (erro absoluto m√©dio)
               - MAPE (erro percentual absoluto m√©dio)
            
            4. **Valida√ß√£o**:
               - Valida√ß√£o in-sample
               - An√°lise de import√¢ncia de features
            """)
            
            st.subheader("‚ö†Ô∏è Limita√ß√µes e Disclaimers")
            
            st.warning("""
            **IMPORTANTE - Limita√ß√µes do Modelo**:
            
            ‚Ä¢ **N√£o captura choques externos**: Crises, pandemias, guerras
            ‚Ä¢ **Baseado em dados hist√≥ricos**: Padr√µes passados podem n√£o se repetir
            ‚Ä¢ **N√£o inclui pol√≠ticas futuras**: Mudan√ßas regulat√≥rias n√£o previstas
            ‚Ä¢ **Intervalo de confian√ßa**: ¬±10-20% nas an√°lises
            
            **Este sistema √© uma ferramenta de apoio √† decis√£o, n√£o substituindo an√°lise especializada em economia.**
            """)
    
    # --- FOOTER ---
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.9em;'>
        <b>üèõÔ∏è Sistema de An√°lise Econ√¥mica "C√≥digo da Riqueza"</b><br>
        Desenvolvido com dados do Banco Mundial e t√©cnicas avan√ßadas de Machine Learning<br>
        Vers√£o Corrigida | ¬© 2024
    </div>
    """, unsafe_allow_html=True)

# --- EXECU√á√ÉO PRINCIPAL ---
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"‚ùå Erro cr√≠tico na aplica√ß√£o: {str(e)}")
        st.exception(e)
        st.info("Por favor, recarregue a p√°gina ou entre em contato com o suporte t√©cnico.")
else:
    # C√≥digo para execu√ß√£o em linha de comando
    print("=" * 80)
    print("üèõÔ∏è  C√ìDIGO DA RIQUEZA - SISTEMA DE AN√ÅLISE ECON√îMICA AVAN√áADA")
    print("=" * 80)
    print()
    print("üöÄ Iniciando sistema...")
    
    try:
        # Carregamento de dados
        print("üì° Conectando ao Banco Mundial...")
        loader = WorldBankDataLoader()
        df_raw = loader.load_with_cache_and_retry()
        
        if df_raw is not None:
            print("‚úÖ Dados carregados com sucesso!")
            
            # Processamento
            print("üîß Processando e limpando dados...")
            processor = DataProcessor()
            df, df_model = processor.process_data(df_raw)
            
            if df is not None and df_model is not None:
                print(f"‚úÖ Processamento conclu√≠do!")
                print(f"   ‚Ä¢ Pa√≠ses: {df['Pa√≠s'].nunique()}")
                print(f"   ‚Ä¢ Observa√ß√µes: {len(df):,}")
                print(f"   ‚Ä¢ Per√≠odo: {df['Ano'].min():.0f}-{df['Ano'].max():.0f}")
                
                # Treinamento de modelos
                print("ü§ñ Treinando modelos de machine learning...")
                trainer = ModelTrainer()
                models_data = trainer.train_and_evaluate(df_model)
                
                print("üèÜ Resultados dos modelos:")
                print(models_data['resultados'].to_string(index=False))
                
                # Exporta√ß√£o
                print("üíæ Exportando resultados...")
                
                # Dados processados
                df_export = df_model.reset_index()
                df_export.to_csv("dados_modelo_codigo_riqueza.csv", index=False)
                print("   ‚úÖ dados_modelo_codigo_riqueza.csv")
                
                # Compara√ß√£o de modelos
                models_data['resultados'].to_csv("comparacao_modelos_codigo_riqueza.csv", index=False)
                print("   ‚úÖ comparacao_modelos_codigo_riqueza.csv")
                
                # Relat√≥rio de qualidade
                quality_report = processor.get_quality_report()
                with open("relatorio_qualidade_dados.txt", "w", encoding="utf-8") as f:
                    f.write("RELAT√ìRIO DE QUALIDADE DOS DADOS\n")
                    f.write("=" * 40 + "\n\n")
                    for stage, data in quality_report.items():
                        f.write(f"{stage.upper()}:\n")
                        for key, value in data.items():
                            f.write(f"  {key}: {value}\n")
                        f.write("\n")
                print("   ‚úÖ relatorio_qualidade_dados.txt")
                
                print()
                print("üéØ SISTEMA PRONTO!")
                print("üíª Execute: streamlit run codigo_riqueza_corrigido.py")
                print()
                print("üîß RECURSOS DISPON√çVEIS:")
                print("   ‚úÖ Sistema robusto de cache e retry")
                print("   ‚úÖ Estrat√©gia multin√≠vel de imputa√ß√£o")
                print("   ‚úÖ 6 modelos de ML comparados")
                print("   ‚úÖ An√°lise de import√¢ncia de vari√°veis")
                print("   ‚úÖ Interface interativa completa")
                
            else:
                print("‚ùå Erro no processamento dos dados")
        else:
            print("‚ùå Erro ao carregar dados do Banco Mundial")
            
    except Exception as e:
        print(f"‚ùå Erro na execu√ß√£o: {str(e)}")
        print("üí° Sugest√£o: Execute com 'streamlit run codigo_riqueza_corrigido.py'")
    
    print()
    print("=" * 80)
